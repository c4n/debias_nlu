{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Model for FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patomp/anaconda3/envs/envFakeNews/lib/python3.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from random import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from my_package.models.traditional.classifier import Classifier\n",
    "from my_package.utils.handcrafted_features.counter import count_negations\n",
    "from my_package.utils.handcrafted_features.overlap import get_lexical_overlap, get_entities_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_FILE = \"../data/paraphrase_identification/qqp.train.jsonl\"\n",
    "DEV_DATA_FILE = \"../data/paraphrase_identification/qqp.dev.jsonl\"\n",
    "TEST_DATA_FILE = \"../data/paraphrase_identification/paws.dev_and_test.jsonl\"\n",
    "\n",
    "WEIGHT_KEY = \"sample_weight\"\n",
    "OUTPUT_TRAIN_DATA_FILE = \"../data/paraphrase_identification/weighted_qqp.train.jsonl\"\n",
    "\n",
    "DOC1_KEY = \"sentence1\"\n",
    "DOC2_KEY = \"sentence2\"\n",
    "LABEL_KEY = \"is_duplicate\"\n",
    "\n",
    "POSSIBLE_LABELS = (\"0\", \"1\")\n",
    "BIAS_CLASS = \"1\"\n",
    "\n",
    "MAX_SAMPLE = -1 # -1 for non-maximal mode or a finite number e.g. 2000\n",
    "DROP_RATE = 0.0\n",
    "TEST_FRAC = 0.2\n",
    "\n",
    "MAX_TEST_SAMPLE = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(\n",
    "    file: str = TRAIN_DATA_FILE,\n",
    "    sent1_key: str = DOC1_KEY,\n",
    "    sent2_key: str = DOC2_KEY,\n",
    "    label_key: str = LABEL_KEY,\n",
    "    drop_rate: float = 0.0\n",
    "):\n",
    "    docs = []\n",
    "    labels = []\n",
    "\n",
    "    N_SAMPLE = 0\n",
    "\n",
    "    with open(file, 'r') as fh:\n",
    "        line = fh.readline()\n",
    "        while line:\n",
    "            if random() > drop_rate:\n",
    "                datapoint = json.loads(line)\n",
    "                docs.append([datapoint[sent1_key], datapoint[sent2_key]])\n",
    "                labels.append(str(datapoint[label_key]))\n",
    "\n",
    "                N_SAMPLE += 1\n",
    "                if MAX_SAMPLE != -1 and N_SAMPLE == MAX_SAMPLE:\n",
    "                    break\n",
    "            line = fh.readline()\n",
    "    print(\"# samples: \", N_SAMPLE)\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples:  200\n"
     ]
    }
   ],
   "source": [
    "docs, labels = read_data(drop_rate=DROP_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['What are the best books for IBPS PO, SBI SO, SBI PO?',\n",
       "  'What are the best books for Bank P.O./IBPS preparation?'],\n",
       " ['What are some of the results of The Congress of Vienna?',\n",
       "  'What were the results of the Congress of Vienna?']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test, labels_train, labels_test = train_test_split(\n",
    "    docs, labels,\n",
    "    stratify=labels, test_size=TEST_FRAC,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors = [\n",
    "    get_lexical_overlap,\n",
    "    get_entities_overlap\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"n_grams\": [1, 2],\n",
    "    \"top_ks\": [50, 50], # select by LMI\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(\n",
    "    possible_labels=POSSIBLE_LABELS,\n",
    "    feature_extractors=feature_extractors,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Top N-grams for sentence 1 ------\n",
      "1-gram LMI:  {'1': {'how': 0.004840899014482804, 'i': 0.0036665460924711676, 'some': 0.0034999784672137494, 'can': 0.0029910741126893603, 'books': 0.002320591279283061, 'weight': 0.002142262579475879, 'find': 0.001624227635084917, 'that': 0.001512734768787952, 'is': 0.001500109029329849, 'should': 0.0014901639813195062, 'lose': 0.0014281750529839192, 'about': 0.0014281750529839192, 'step': 0.0014281750529839192, 'circuit': 0.0014281750529839192, 'watch': 0.0014281750529839192, 'hire': 0.0014281750529839192, 'hacker': 0.0014281750529839192, 'life': 0.0014281750529839192, 'under': 0.0014281750529839192, 'movies': 0.0014281750529839192, 'what': 0.0014040516549593271, 'instagram': 0.000941422222121777, '2016': 0.000941422222121777, 'girl': 0.000941422222121777, 'after': 0.000941422222121777, 'quora': 0.000941422222121777, 'so': 0.000941422222121777, 'phone': 0.000941422222121777, 'with': 0.0008940983887917038, 'quickly': 0.0007140875264919596, 'weeks': 0.0007140875264919596, 'see': 0.0007140875264919596, 'boyfriend': 0.0007140875264919596, 'views': 0.0007140875264919596, 'u.s.a': 0.0007140875264919596, 'presedential': 0.0007140875264919596, 'elections': 0.0007140875264919596, 'sexual': 0.0007140875264919596, 'dimorphism': 0.0007140875264919596, 'prevent': 0.0007140875264919596, 'social': 0.0007140875264919596, 'equality': 0.0007140875264919596, 'sexes': 0.0007140875264919596, 'procedure': 0.0007140875264919596, 'start': 0.0007140875264919596, 'up': 0.0007140875264919596, 'changes': 0.0007140875264919596, 'noticed': 0.0007140875264919596, 'started': 0.0007140875264919596, 'meditating': 0.0007140875264919596}, '0': {'the': 0.0023617943412360524, 'a': 0.0018818202602385516, 'good': 0.001742463286372323, 'or': 0.0015246553755757827, 'it': 0.0011768784812996526, 'if': 0.0011768784812996526, 'people': 0.001089039553982702, 'there': 0.0008712316431861615, 'way': 0.0008712316431861615, 'most': 0.0008712316431861615, 'not': 0.0008712316431861615, 'us': 0.0008712316431861615, 'as': 0.0008712316431861615, 'use': 0.0008712316431861615, 'and': 0.0007534620280515974, 'be': 0.0007516829515958386, 'more': 0.0006534237323896212, 'hate': 0.0006534237323896212, 'crush': 0.0006534237323896212, 'her': 0.0006534237323896212, 'difference': 0.0006534237323896212, 'water': 0.0006534237323896212, 'made': 0.0006534237323896212, 'them': 0.0006534237323896212, 'math': 0.0006534237323896212, 'between': 0.0005418560101833183, 'lovers': 0.00043561582159308077, 'dogs': 0.00043561582159308077, 'society': 0.00043561582159308077, 'first': 0.00043561582159308077, 'still': 0.00043561582159308077, 'love': 0.00043561582159308077, 'created': 0.00043561582159308077, 'layer': 0.00043561582159308077, 'value': 0.00043561582159308077, 'theory': 0.00043561582159308077, 'foreign': 0.00043561582159308077, 'stop': 0.00043561582159308077, 'all': 0.00043561582159308077, 'account': 0.00043561582159308077, 'their': 0.00043561582159308077, 'much': 0.00043561582159308077, 'website': 0.00043561582159308077, 'lie': 0.00043561582159308077, 'price': 0.00043561582159308077, 'kindle': 0.00043561582159308077, 'long': 0.00043561582159308077, 'primary': 0.00043561582159308077, 'income': 0.00043561582159308077, 'tax': 0.00043561582159308077}} \n",
      "\n",
      "2-gram LMI:  {'1': {'how_can': 0.005255116199897179, 'are_some': 0.0032149564455644986, 'what_are': 0.0031012510837847515, 'can_i': 0.00279519343497555, 'how_do': 0.0024735745800423237, 'i_find': 0.0018421057838507427, 'do_i': 0.0017929510088464148, 'lose_weight': 0.0016101184275496064, 'on_instagram': 0.0016101184275496064, 'how_is': 0.0016101184275496064, 'i_hire': 0.0016101184275496064, 'with_a': 0.0016101184275496064, 'can_one': 0.0016101184275496064, 'why_is': 0.001397596717487775, 'on_quora': 0.0010716521485214995, 'should_i': 0.0010344063653085825, 'i_lose': 0.0008050592137748032, 'weight_quickly': 0.0008050592137748032, 'quickly_in': 0.0008050592137748032, 'in_2': 0.0008050592137748032, '2_weeks': 0.0008050592137748032, 'i_see': 0.0008050592137748032, 'see_who': 0.0008050592137748032, 'who_my': 0.0008050592137748032, 'my_boyfriend': 0.0008050592137748032, 'boyfriend_views': 0.0008050592137748032, 'views_on': 0.0008050592137748032, 'win_the': 0.0008050592137748032, 'the_u.s.a': 0.0008050592137748032, 'u.s.a_presedential': 0.0008050592137748032, 'presedential_elections': 0.0008050592137748032, 'elections_of': 0.0008050592137748032, 'of_2016': 0.0008050592137748032, 'do_about': 0.0008050592137748032, 'about_this': 0.0008050592137748032, 'this_girl': 0.0008050592137748032, 'girl_i': 0.0008050592137748032, 'i_like': 0.0008050592137748032, 'does_sexual': 0.0008050592137748032, 'sexual_dimorphism': 0.0008050592137748032, 'dimorphism_prevent': 0.0008050592137748032, 'prevent_social': 0.0008050592137748032, 'social_equality': 0.0008050592137748032, 'equality_between': 0.0008050592137748032, 'the_sexes': 0.0008050592137748032, 'the_step': 0.0008050592137748032, 'step_by': 0.0008050592137748032, 'by_step': 0.0008050592137748032, 'step_procedure': 0.0008050592137748032, 'procedure_to': 0.0008050592137748032}, '0': {'is_the': 0.0015071560095894342, 'is_a': 0.0011722337182655846, 'a_good': 0.0011722337182655846, 'in_the': 0.0009377869746124676, 'way_to': 0.0009377869746124676, 'the_difference': 0.0007033402309593507, 'difference_between': 0.0007033402309593507, 'to_get': 0.0007033402309593507, 'you_have': 0.0007033402309593507, 'why_do': 0.0007033402309593507, 'which_is': 0.0007033402309593507, 'the_most': 0.0007033402309593507, 'i_use': 0.0007033402309593507, 'lovers_who': 0.0004688934873062338, 'who_hate': 0.0004688934873062338, 'do_they': 0.0004688934873062338, 'the_value': 0.0004688934873062338, 'value_of': 0.0004688934873062338, 'used_to': 0.0004688934873062338, 'all_the': 0.0004688934873062338, 'how_much': 0.0004688934873062338, 'does_it': 0.0004688934873062338, 'what_the': 0.0004688934873062338, 'where_are': 0.0004688934873062338, 'and_how': 0.0004688934873062338, 'are_they': 0.0004688934873062338, 'if_the': 0.0004688934873062338, 'a_kindle': 0.0004688934873062338, 'of_a': 0.0004688934873062338, 'what_makes': 0.0004688934873062338, 'how_many': 0.0004688934873062338, 'might_you': 0.0004688934873062338, 'to_a': 0.0004688934873062338, 'good_solar': 0.0004688934873062338, 'solar_panel': 0.0004688934873062338, 'panel_installation': 0.0004688934873062338, 'installation_provider': 0.0004688934873062338, 'california_ca': 0.0004688934873062338, 'do_the': 0.0004688934873062338, 'i_am': 0.0004688934873062338, 'is_there': 0.0004688934873062338, 'did_the': 0.0004688934873062338, 'you_do': 0.0004688934873062338, 'if_a': 0.0004688934873062338, 'best_classified': 0.0004688934873062338, 'classified_sites': 0.0004688934873062338, 'sites_in': 0.0004688934873062338, 'are_syriac': 0.0002344467436531169, 'syriac_people': 0.0002344467436531169, 'people_arabs': 0.0002344467436531169}} \n",
      "\n",
      "------ Top N-grams for sentence 2 ------\n",
      "1-gram LMI:  {'1': {'how': 0.002793569571713981, 'i': 0.002631404140110209, 'what': 0.0023766185137026863, 'find': 0.0022507102462013297, 'books': 0.0022507102462013297, 'weight': 0.002069474652709476, 'some': 0.0020666901479135993, 'is': 0.001938373582595507, 'was': 0.0015777104262961752, 'point': 0.0015777104262961752, 'where': 0.0015777104262961752, 'for': 0.0015314807353584206, 'are': 0.0014537391840889287, 'lose': 0.0013796497684729838, 'tiny': 0.0013796497684729838, 'hacker': 0.0013796497684729838, 'learn': 0.0013796497684729838, 'movies': 0.0013796497684729838, 'okay': 0.0013796497684729838, 'best': 0.0012028071551873879, 'can': 0.0009691867912977535, 'my': 0.0009549114942482722, 'instagram': 0.0009175812692044205, 'girl': 0.0009175812692044205, 'start': 0.0009175812692044205, 'used': 0.0009175812692044205, 'life': 0.0009175812692044205, 'quora': 0.0009175812692044205, 'so': 0.0009175812692044205, 'buy': 0.0009175812692044205, 'phone': 0.0009175812692044205, 'that': 0.00088460767739333, 'your': 0.00088460767739333, 'viewed': 0.0006898248842364919, 'elections': 0.0006898248842364919, '2016': 0.0006898248842364919, 'sexual': 0.0006898248842364919, 'dimorphism': 0.0006898248842364919, 'enough': 0.0006898248842364919, 'conclude': 0.0006898248842364919, 'gender': 0.0006898248842364919, 'equality': 0.0006898248842364919, 'impossible': 0.0006898248842364919, 'since': 0.0006898248842364919, 'started': 0.0006898248842364919, 'meditating': 0.0006898248842364919, 'relation': 0.0006898248842364919, 'coriolis': 0.0006898248842364919, 'effect': 0.0006898248842364919, 'hurricanes': 0.0006898248842364919}, '0': {'the': 0.002239898155838886, 'and': 0.0011149490643437559, 'an': 0.0010759975209122168, 'all': 0.0010080626547193763, 'a': 0.0008698304570686362, 'ca': 0.0008064501237755009, 'need': 0.0008064501237755009, 'way': 0.0008064501237755009, 'their': 0.0008064501237755009, 'as': 0.0008064501237755009, 'we': 0.0008064501237755009, 'good': 0.0007854322889453842, 'does': 0.0006826643144589494, 'get': 0.0006826643144589494, 'am': 0.0006048375928316257, 'her': 0.0006048375928316257, 'foreign': 0.0006048375928316257, 'stop': 0.0006048375928316257, 'one': 0.0006048375928316257, 'makes': 0.0006048375928316257, 'income': 0.0006048375928316257, 'know': 0.0006048375928316257, 'to': 0.0005820279773381937, 'not': 0.000488628019978765, 'do': 0.00042085320550922986, 'people': 0.00040322506188775046, 'lovers': 0.00040322506188775046, 'cats': 0.00040322506188775046, 'dogs': 0.00040322506188775046, 'dog': 0.00040322506188775046, 'because': 0.00040322506188775046, 'crush': 0.00040322506188775046, 'told': 0.00040322506188775046, \"n't\": 0.00040322506188775046, 'energy': 0.00040322506188775046, 'created': 0.00040322506188775046, 'force': 0.00040322506188775046, 'obc': 0.00040322506188775046, 'primary': 0.00040322506188775046, 'java': 0.00040322506188775046, 'much': 0.00040322506188775046, 'water': 0.00040322506188775046, 's': 0.00040322506188775046, 'ground': 0.00040322506188775046, 'food': 0.00040322506188775046, 'android': 0.00040322506188775046, 'xbox': 0.00040322506188775046, 'most': 0.00040322506188775046, 'end': 0.00040322506188775046, 'lie': 0.00040322506188775046}} \n",
      "\n",
      "2-gram LMI:  {'1': {'are_some': 0.0031195461625750163, 'i_find': 0.003096537838226181, 'how_can': 0.00270215472232305, 'can_i': 0.00270215472232305, 'what_are': 0.0024615240758459334, 'how_do': 0.0024124020595175403, 'do_i': 0.0017908847828573995, 'a_tiny': 0.0015482689191130905, 'tiny_point': 0.0015482689191130905, 'on_quora': 0.0015482689191130905, 'it_okay': 0.0015482689191130905, 'okay_for': 0.0015482689191130905, 'where_can': 0.0015482689191130905, 'of_the': 0.0013616028324013147, 'the_best': 0.0010628570452071748, 'for_a': 0.0010398487208583389, 'for_the': 0.0010398487208583389, 'some_of': 0.0010398487208583389, 'i_lose': 0.0007741344595565453, 'lose_my': 0.0007741344595565453, 'my_weight': 0.0007741344595565453, 'weight_quickly': 0.0007741344595565453, 'who_has': 0.0007741344595565453, 'has_viewed': 0.0007741344595565453, 'viewed_my': 0.0007741344595565453, 'my_instagram': 0.0007741344595565453, 'win_the': 0.0007741344595565453, 'the_us': 0.0007741344595565453, 'us_elections': 0.0007741344595565453, 'elections_2016': 0.0007741344595565453, 'do_about': 0.0007741344595565453, 'about_a': 0.0007741344595565453, 'girl_i': 0.0007741344595565453, 'i_like': 0.0007741344595565453, 'is_sexual': 0.0007741344595565453, 'sexual_dimorphism': 0.0007741344595565453, 'dimorphism_enough': 0.0007741344595565453, 'enough_to': 0.0007741344595565453, 'to_conclude': 0.0007741344595565453, 'conclude_that': 0.0007741344595565453, 'that_gender': 0.0007741344595565453, 'gender_equality': 0.0007741344595565453, 'equality_is': 0.0007741344595565453, 'is_impossible': 0.0007741344595565453, 'are_necessary': 0.0007741344595565453, 'necessary_steps': 0.0007741344595565453, 'steps_to': 0.0007741344595565453, 'to_start': 0.0007741344595565453, 'start_a': 0.0007741344595565453, 'a_start': 0.0007741344595565453}, '0': {'is_a': 0.0009226840284314191, 'way_to': 0.0008621229820760486, 'i_am': 0.0006465922365570364, 'i_need': 0.0006465922365570364, 'do_the': 0.0006465922365570364, 'do_you': 0.0006465922365570364, 'can_we': 0.0006465922365570364, 'a_good': 0.0005061127972064887, 'why_do': 0.0004310614910380243, 'my_crush': 0.0004310614910380243, 'i_ca': 0.0004310614910380243, \"ca_n't\": 0.0004310614910380243, 'what_the': 0.0004310614910380243, 'not_be': 0.0004310614910380243, 'be_created': 0.0004310614910380243, 'who_is': 0.0004310614910380243, 'how_much': 0.0004310614910380243, 'need_to': 0.0004310614910380243, 'to_the': 0.0004310614910380243, 'to_get': 0.0004310614910380243, 'out_what': 0.0004310614910380243, 'from_the': 0.0004310614910380243, 'the_xbox': 0.0004310614910380243, 'xbox_one': 0.0004310614910380243, 'in_india': 0.0004310614910380243, 'and_when': 0.0004310614910380243, 'to_do': 0.0004310614910380243, 'the_same': 0.0004310614910380243, 'as_the': 0.0004310614910380243, 'what_makes': 0.0004310614910380243, 'makes_them': 0.0004310614910380243, 'to_download': 0.0004310614910380243, 'which_is': 0.0004310614910380243, 'good_solar': 0.0004310614910380243, 'solar_panel': 0.0004310614910380243, 'panel_installation': 0.0004310614910380243, 'installation_provider': 0.0004310614910380243, 'california_ca': 0.0004310614910380243, 'of_an': 0.0004310614910380243, 'a_us': 0.0004310614910380243, 'how_did': 0.0004310614910380243, 'did_the': 0.0004310614910380243, 'what_will': 0.0004310614910380243, 'the_future': 0.0004310614910380243, 'future_of': 0.0004310614910380243, 'best_way': 0.0004310614910380243, 'when_to': 0.0004310614910380243, 'ready_to': 0.0004310614910380243, 'to_preserve': 0.0004310614910380243, 'of_this': 0.0004310614910380243}} \n",
      "\n",
      "n_features: 402\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(docs_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': 0.693356785861582, '1': 0.306643214138418},\n",
       " {'0': 0.7805909204344456, '1': 0.21940907956555442}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inferential Examples\n",
    "x = [['Roman Atwood is a content creator .',\n",
    "  'He is best known for his vlogs , where he posts updates about his life on a daily basis .'],\n",
    " ['Roman Atwood is a content creator .',\n",
    "  \"He also has another YouTube channel called `` RomanAtwood '' , where he posts pranks .\"]] \n",
    "classifier.inference(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original train set: 0.675\n",
      "F1-pos on original train set: 0.316\n",
      "F1-neg on original train set: 0.787\n"
     ]
    }
   ],
   "source": [
    "y_preds = classifier.predict(docs_test)\n",
    "\n",
    "print(\"Accuracy on original train set: %.3f\"% accuracy_score(labels_test, y_preds))\n",
    "print(\"F1-pos on original train set: %.3f\"% f1_score(labels_test, y_preds, pos_label='1'))\n",
    "print(\"F1-neg on original train set: %.3f\"% f1_score(labels_test, y_preds, pos_label='0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On original test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples:  200\n"
     ]
    }
   ],
   "source": [
    "eval_docs, eval_labels = read_data(DEV_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original test set: 0.665\n",
      "F1-pos on original test set: 0.396\n",
      "F1-neg on original test set: 0.768\n"
     ]
    }
   ],
   "source": [
    "y_preds = classifier.predict(eval_docs)\n",
    "\n",
    "print(\"Accuracy on original test set: %.3f\"% accuracy_score(eval_labels, y_preds))\n",
    "print(\"F1-pos on original test set: %.3f\"% f1_score(eval_labels, y_preds, pos_label='1'))\n",
    "print(\"F1-neg on original test set: %.3f\"% f1_score(eval_labels, y_preds, pos_label='0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On symmetric (challenge) test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples:  200\n"
     ]
    }
   ],
   "source": [
    "eval_docs, eval_labels = read_data(TEST_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on challenge test set: 0.530\n",
      "F1-pos on challenge test set: 0.347\n",
      "F1-neg on challenge test set: 0.633\n"
     ]
    }
   ],
   "source": [
    "y_preds = classifier.predict(eval_docs)\n",
    "\n",
    "print(\"Accuracy on challenge test set: %.3f\"% accuracy_score(eval_labels, y_preds))\n",
    "print(\"F1-pos on challenge test set: %.3f\"% f1_score(eval_labels, y_preds, pos_label='1'))\n",
    "print(\"F1-neg on challenge test set: %.3f\"% f1_score(eval_labels, y_preds, pos_label='0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write predicted probability to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(prob_score_bias_class: float, ground_truth_label: str, bias_label: str = BIAS_CLASS) -> float:\n",
    "    if ground_truth_label == bias_label:\n",
    "        return 1/prob_score_bias_class\n",
    "    return 1/(1-prob_score_bias_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases\n",
    "def test_bias_label():\n",
    "    weight = get_weight(0.2, \"A\", bias_label=\"A\")\n",
    "    np.testing.assert_almost_equal(1/0.2, weight, 5)\n",
    "    \n",
    "def test_not_bias_label():\n",
    "    weight = get_weight(0.2, \"B\", bias_label=\"A\")\n",
    "    np.testing.assert_almost_equal(1/0.8, weight, 5)\n",
    "    \n",
    "test_bias_label()\n",
    "test_not_bias_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_output = open(OUTPUT_TRAIN_DATA_FILE, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLE = 0\n",
    "\n",
    "with open(TRAIN_DATA_FILE, 'r') as fh:\n",
    "    line = fh.readline()\n",
    "    while line:\n",
    "        datapoint = json.loads(line)\n",
    "        x = [[datapoint[DOC1_KEY], datapoint[DOC2_KEY]]]\n",
    "        \n",
    "        prob = classifier.inference(x)[0][BIAS_CLASS]\n",
    "        weight = get_weight(\n",
    "            prob_score_bias_class=prob,\n",
    "            ground_truth_label=datapoint[LABEL_KEY],\n",
    "            bias_label=BIAS_CLASS\n",
    "        )\n",
    "        if datapoint.get(\"weight\", None) != None:\n",
    "            del datapoint[\"weight\"] # only for fever\n",
    "        f_output.write(\"%s\\n\"%json.dumps({**datapoint, WEIGHT_KEY: weight, \"prob\": prob}))\n",
    "\n",
    "        N_SAMPLE += 1\n",
    "        if MAX_SAMPLE != -1 and N_SAMPLE == MAX_SAMPLE:\n",
    "            break\n",
    "        line = fh.readline()\n",
    "        \n",
    "f_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
