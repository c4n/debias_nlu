{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Model for FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import random\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from my_package.models.traditional.classifier import Classifier\n",
    "from my_package.utils.handcrafted_features.counter import count_negations\n",
    "from my_package.utils.handcrafted_features.overlap import get_lexical_overlap, get_entities_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMMY_PREFIX = \"\" # \"sample_\" for example and \"\" for the real one\n",
    "\n",
    "TRAIN_DATA_FILE = \"../data/paraphrase_identification/%sqqp.train.jsonl\"%DUMMY_PREFIX\n",
    "VAL_DATA_FILE = \"../data/paraphrase_identification/%sqqp.val.jsonl\"%DUMMY_PREFIX\n",
    "DEV_DATA_FILE = \"../data/paraphrase_identification/%sqqp.dev.jsonl\"%DUMMY_PREFIX\n",
    "TEST_DATA_FILE = \"../data/paraphrase_identification/paws.dev_and_test.jsonl\"\n",
    "\n",
    "WEIGHT_KEY = \"sample_weight\"\n",
    "OUTPUT_VAL_DATA_FILe = \"../data/paraphrase_identification/%sweighted_qqp.val.jsonl\"%DUMMY_PREFIX\n",
    "OUTPUT_TRAIN_DATA_FILE = \"../data/paraphrase_identification/%sweighted_qqp.train.jsonl\"%DUMMY_PREFIX\n",
    "SAVED_MODEL_PATH = \"../results/qqp/bias_model\"\n",
    "\n",
    "DOC1_KEY = \"sentence1\"\n",
    "DOC2_KEY = \"sentence2\"\n",
    "LABEL_KEY = \"is_duplicate\"\n",
    "\n",
    "POSSIBLE_LABELS = (\"0\", \"1\")\n",
    "BIAS_CLASS = \"1\"\n",
    "\n",
    "MAX_SAMPLE = -1 # -1 for non-maximal mode or a finite number e.g. 2000\n",
    "DROP_RATE = 0.0\n",
    "TEST_FRAC = 0.2\n",
    "\n",
    "MAX_TEST_SAMPLE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_prob_to_index(x: List[Dict[str, float]]) -> List[float]:\n",
    "    return [\n",
    "        x[\"0\"],\n",
    "        x[\"1\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(\n",
    "    file: str = TRAIN_DATA_FILE,\n",
    "    sent1_key: str = DOC1_KEY,\n",
    "    sent2_key: str = DOC2_KEY,\n",
    "    label_key: str = LABEL_KEY,\n",
    "    drop_rate: float = 0.0\n",
    "):\n",
    "    docs = []\n",
    "    labels = []\n",
    "\n",
    "    N_SAMPLE = 0\n",
    "\n",
    "    with open(file, 'r') as fh:\n",
    "        line = fh.readline()\n",
    "        while line:\n",
    "            if random() > drop_rate:\n",
    "                datapoint = json.loads(line)\n",
    "                docs.append([datapoint[sent1_key], datapoint[sent2_key]])\n",
    "                labels.append(str(datapoint[label_key]))\n",
    "\n",
    "                N_SAMPLE += 1\n",
    "                if MAX_SAMPLE != -1 and N_SAMPLE == MAX_SAMPLE:\n",
    "                    break\n",
    "            line = fh.readline()\n",
    "    print(\"# samples: \", N_SAMPLE)\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples:  394287\n"
     ]
    }
   ],
   "source": [
    "docs, labels = read_data(drop_rate=DROP_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['How can I stop my dog from chewing my shoes?',\n",
       "  'How do you stop a English Bulldog/Pitbull mix puppy from biting my shoes?'],\n",
       " ['What are the most interesting products and innovations that Guess is coming out with in 2016?',\n",
       "  'What are the most interesting products and innovations that Twitter is coming out with in 2016?']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test, labels_train, labels_test = train_test_split(\n",
    "    docs, labels,\n",
    "    stratify=labels, test_size=TEST_FRAC,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors = [\n",
    "    get_lexical_overlap,\n",
    "    get_entities_overlap\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"n_grams\": [1, 2],\n",
    "    \"top_ks\": [50, 50], # select by LMI\n",
    "    \"verbose\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(\n",
    "    possible_labels=POSSIBLE_LABELS,\n",
    "    feature_extractors=feature_extractors,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Top N-grams for sentence 1 ------\n",
      "1-gram LMI:  {'1': {'how': 0.003131597238347227, 'do': 0.002285449958695732, 'can': 0.001863018506616515, 'you': 0.0010957448135881257, 'i': 0.0010934890462615734, '500': 0.0010924789905773387, 'quora': 0.0008671009729796184, 'notes': 0.0008354251104414944, 'best': 0.0007808110606229144, 'life': 0.0007216823342085798, '1000': 0.0007171122063811738, 'money': 0.0007014760067833251, 'your': 0.0006488218292881769, 'improve': 0.0006406790898520766, 'war': 0.0006391822526546039, 'who': 0.0006346506392816293, 'think': 0.0006034940326607351, '2000': 0.0005783712303056499, 'rupee': 0.0005783712303056499, 'rs': 0.000557622236268245, 'ever': 0.0005436145423007438, 'really': 0.0005250121260953952, 'english': 0.0005149166155177826, 'is': 0.00048464443080930474, 'battle': 0.0004498442902377277, 'my': 0.00041647518841883704, 'ways': 0.00041365486451378685, 'india': 0.00040373374784453655, 'president': 0.00039213955954272965, 'currency': 0.00038558082020376656, 'get': 0.0003825580787148385, 'donald': 0.00037815682669955955, 'trump': 0.0003570590040723181, 'make': 0.0003512090956535254, 'what': 0.00034296433802409723, '2017': 0.0003335351233401377, 'will': 0.00032636762010314753, 'way': 0.00032300412329958945, 'win': 0.0003213173501698055, 'note': 0.0003213173501698055, 'could': 0.0003118786005691316, 'on': 0.00031166463185325013, 'hillary': 0.00030934996760134675, 'one': 0.0002999914339312621, 'time': 0.0002980999693948064, 'lose': 0.0002884510900416663, 'learning': 0.0002884510900416663, 'possible': 0.0002814541892978043, 'weight': 0.0002718072711503719, 'period': 0.0002700198551515301}, '0': {'in': 0.0011311766106548056, 'to': 0.0006538954169699336, 'it': 0.0006304104671036319, 'does': 0.0006077932550444655, 'and': 0.0005775003598916282, 'the': 0.0005579760815037464, 'or': 0.000525916303387589, 'not': 0.0005153402378171843, 'of': 0.0005008623355251401, 'a': 0.0004316160728172019, 'for': 0.000388792116880032, 'mean': 0.00034679759052410757, 'like': 0.0003386253902111553, 'day': 0.000324499277455412, 'someone': 0.0002965048718929267, 'when': 0.000282235974002411, 'they': 0.0002792138433352173, 'at': 0.0002645760832902162, 'them': 0.0002595994219643296, 'where': 0.00024994035098718933, 'from': 0.0002450248561504831, 'products': 0.00023796613680063548, 'between': 0.00023523234864697694, 'as': 0.0002338573633936611, 'out': 0.00021885259779134744, 'much': 0.00019755784263652764, 'different': 0.0001946995664732472, 'email': 0.0001946995664732472, 'messenger': 0.0001946995664732472, 'years': 0.0001946995664732472, 'me': 0.00018981575090264722, 'want': 0.00017655030504998905, 'why': 0.000170024846867608, 'now': 0.00016270042813554863, 'used': 0.00015550802823707162, 'science': 0.00015550802823707162, 'watch': 0.00015143299614585893, 'california': 0.00015143299614585893, 'youtube': 0.00015143299614585893, 'working': 0.00015143299614585893, 'say': 0.00015143299614585893, 'coming': 0.00015143299614585893, 'current': 0.00015143299614585893, 'price': 0.00015143299614585893, 'majors': 0.00015143299614585893, 'true': 0.00015143299614585893, 'employees': 0.00015143299614585893, 'engineer': 0.00015143299614585893, 'run': 0.00015143299614585893, 'his': 0.00015143299614585893}} \n",
      "\n",
      "2-gram LMI:  {'1': {'how_can': 0.0021833415234007916, 'can_i': 0.001587782753995626, 'how_do': 0.0013881410327595469, 'do_i': 0.00107708903475682, '500_and': 0.0009284817279682483, 'the_best': 0.0008641738623684957, 'do_you': 0.0007710680860028251, 'improve_my': 0.0006014707137017897, 'and_1000': 0.0005713733710573835, 'on_quora': 0.0005561769140903748, 'what_is': 0.0005133329656558605, 'you_have': 0.000460981409489535, 'i_make': 0.000460981409489535, 'i_improve': 0.000460981409489535, 'rupee_notes': 0.00042853002829303766, 'i_get': 0.00042837115889045834, 'donald_trump': 0.0004235707245534495, 'ways_to': 0.0003911643026084651, 'what_should': 0.00038608100727162723, 'you_think': 0.0003713347973881122, 'battle_of': 0.00035710835691086476, '1000_rupee': 0.00035710835691086476, 'rs_500': 0.00035710835691086476, 'do_to': 0.0003455565102885847, 'and_how': 0.0003311864607702271, 'will_be': 0.00032179003480403354, 'why_do': 0.00031463691445660595, 'make_money': 0.00030073535685089486, 'of_the': 0.00029067809623291096, 'people_think': 0.00028568668552869176, 'the_battle': 0.00028568668552869176, 'currency_notes': 0.00028568668552869176, 'world_war': 0.00028568668552869176, 'lose_weight': 0.00028568668552869176, 'for_2017': 0.00028568668552869176, 'views_on': 0.00028568668552869176, 'one_thing': 0.00028568668552869176, 'know_about': 0.00028568668552869176, 'i_do': 0.00028558077259363887, 'way_to': 0.0002832997041773326, 'be_a': 0.000266634310204627, 'of_life': 0.0002530726644301236, 'get_rid': 0.0002530726644301236, 'to_improve': 0.0002530726644301236, 'in_india': 0.00023860876240332248, 'possible_to': 0.00023198593015919032, 'a_blog': 0.0002304907047447675, 'things_that': 0.0002304907047447675, 'if_the': 0.0002304907047447675, \"n't_know\": 0.0002304907047447675}, '0': {'what_does': 0.0003964755247383683, 'does_it': 0.00037331084983666167, 'if_i': 0.00032705173235248705, 'in_the': 0.00031347006675870847, 'how_much': 0.00029519135107529843, 'as_a': 0.0002574255149439122, 'where_can': 0.00022016509665223307, 'it_mean': 0.00021062087586320088, 'are_the': 0.0002097212183212846, 'i_have': 0.00018721855632284522, 'why_are': 0.00016643737267441693, 'i_want': 0.0001638162367824896, 'for_a': 0.0001558456073972107, 'do_people': 0.00015198228573764052, 'would_you': 0.00014379030801206952, 'the_top': 0.00014041391724213393, 'between_the': 0.00014041391724213393, 'in_chennai': 0.00014041391724213393, 'why_is': 0.00013901933822871353, 'the_difference': 0.00013469569501251932, 'the_world': 0.00012894978597771708, 'much_does': 0.00012894978597771708, 'did_the': 0.00011701159770177827, 'to_have': 0.00011701159770177827, 'to_use': 0.00011701159770177827, 'able_to': 0.00011701159770177827, 'definition_of': 0.00011701159770177827, 'most_interesting': 0.00011701159770177827, 'in_2016': 0.00011701159770177827, 'as_an': 0.00011701159770177827, 'or_a': 0.00011701159770177827, 'or_not': 0.00011701159770177827, 'new_employees': 0.00011701159770177827, 'what_kind': 0.00011701159770177827, 'to_be': 0.00011523989213249514, 'i_am': 0.00011523989213249514, 'difference_between': 0.00010969360203316253, 'need_to': 0.00010601401376773122, 'it_be': 0.00010601401376773122, 'of_a': 0.00010601401376773122, 'in_my': 9.893722864538132e-05, 'want_to': 9.893722864538132e-05, 'of_your': 9.360927816142261e-05, 'are_particularly': 9.360927816142261e-05, 'and_moral': 9.360927816142261e-05, 'me_to': 9.360927816142261e-05, 'be_able': 9.360927816142261e-05, 'of_using': 9.360927816142261e-05, 'the_definition': 9.360927816142261e-05, 'the_differences': 9.360927816142261e-05}} \n",
      "\n",
      "------ Top N-grams for sentence 2 ------\n",
      "1-gram LMI:  {'1': {'how': 0.002698986637228657, 'the': 0.0019497633429249707, 'can': 0.001625646469490935, 'do': 0.0013753454933430136, 'what': 0.0011344742234347558, 'notes': 0.0009782077872751102, 'will': 0.0009277609840873726, 'quora': 0.0009264518443537732, 'best': 0.0008486514498470849, '1000': 0.0008477800823050954, '500': 0.0007936897090527016, 'are': 0.0006971965357051995, 'really': 0.000696227011611862, 'why': 0.0006636172297350706, 'you': 0.0006267540527051951, 'improve': 0.0006182246183118797, 'money': 0.0006182246183118797, 'rupee': 0.0005869246723650661, 'life': 0.0005612815796262254, 'trump': 0.0005577195688138632, 'english': 0.0005333576518294395, '2000': 0.0005217108198800587, 'war': 0.0005093877840675771, 'ways': 0.0004729604832285838, 'your': 0.0004724186766301323, 'ban': 0.00045649696739505136, 'we': 0.00044704983902413373, 'donald': 0.0004244898200563142, 'be': 0.00039905382305085475, 'battle': 0.0003912831149100441, 'increase': 0.000378673941044043, 'on': 0.00037368582813478694, \"n't\": 0.0003690020814949882, 'make': 0.0003662924028827898, 'rs': 0.0003636640597935455, 'win': 0.0003577264885917083, 'question': 0.0003577264885917083, 'did': 0.0003448527297225289, 'america': 0.00032606926242503674, 'economy': 0.00032606926242503674, 'note': 0.00032606926242503674, 'ever': 0.0003221252381721109, 'india': 0.0003166228659405293, 'under': 0.0003163181673517563, 'think': 0.0002961898846421949, 'blog': 0.0002943715190024204, '2017': 0.0002943715190024204, 'book': 0.000274886971482935, 'created': 0.000274886971482935, 'writing': 0.000274886971482935}, '0': {'a': 0.0020960109239841654, 'to': 0.0014235976944662067, 'does': 0.0008914712017699005, 'an': 0.0006123541315947184, 'from': 0.0005699599674759345, 'not': 0.0005552635229777975, 'for': 0.0005118642326603231, 'as': 0.0004879036404093898, 'much': 0.00048174423070400927, 'in': 0.0004526972704389557, 'should': 0.00042436569997105546, 'they': 0.00042154400322382517, 'or': 0.00040556783313047413, 'have': 0.0003616183562675636, 'mean': 0.0003457790097315348, 'at': 0.00029268510214235967, 'it': 0.0002844182341437469, 'and': 0.00027440284899611097, 'which': 0.00023416207834854613, 'college': 0.000231866374394919, 'someone': 0.00023079226538119955, 'person': 0.00021993352375978317, 'so': 0.00021077238282429456, 'many': 0.00020520837642416218, 'year': 0.00020520837642416218, 'first': 0.00019901708606666975, 'most': 0.00019637656456452662, 'friend': 0.00018970885177766098, 'employees': 0.00018970885177766098, 'different': 0.00018970885177766098, '5': 0.00017812850752130553, 'no': 0.00017812850752130553, 'body': 0.00017812850752130553, 'like': 0.00017322918968401196, 'old': 0.00016957659100303915, 'police': 0.00016863009046903197, 'play': 0.00016863009046903197, 'using': 0.00016863009046903197, 'web': 0.00016863009046903197, 'am': 0.00016585136930684764, 'job': 0.00016263454680312992, 'but': 0.00016263454680312992, 'his': 0.00015727563745082594, 'way': 0.00015205050954865957, 'us': 0.00015128630415154842, 'into': 0.00014908751075676778, 'foreign': 0.00014755132916040298, 'house': 0.00014755132916040298, 'women': 0.00014755132916040298, 'home': 0.00014755132916040298}} \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram LMI:  {'1': {'how_do': 0.0016762468815476141, 'how_can': 0.0016395348572630377, 'do_i': 0.001461593834207281, 'what_is': 0.0008912696773281356, 'can_i': 0.0008527877422811793, 'what_are': 0.0007193761031778532, 'the_best': 0.0007018282994500884, 'on_quora': 0.0006347783285563914, 'how_did': 0.0005441703883386535, 'is_the': 0.0005237711414931545, 'will_the': 0.0005225435351750253, '500_and': 0.0005080849634338861, 'and_1000': 0.0005080849634338861, 'ways_to': 0.0004757183909928511, 'donald_trump': 0.0004757183909928511, 'i_get': 0.00044938680525354415, 'are_some': 0.0004389830245536441, 'are_the': 0.0004388604422926, '1000_notes': 0.00043550139722904526, 'the_ban': 0.00043550139722904526, 'can_we': 0.0004235141376241519, 'make_money': 0.00039956599495776857, 'do_you': 0.00039755334475431226, 'the_indian': 0.00037844729328952577, 'can_one': 0.00036291783102420435, 'ban_of': 0.00036291783102420435, 'rupee_notes': 0.00036291783102420435, 'some_good': 0.00035407073805783734, 'improve_my': 0.00035407073805783734, 'your_life': 0.0003066839291076185, 'be_a': 0.000304502574208255, 'a_blog': 0.0002903342648193635, 'the_battle': 0.0002903342648193635, 'battle_of': 0.0002903342648193635, '1000_rupee': 0.0002903342648193635, 'the_usa': 0.0002903342648193635, 'world_war': 0.0002903342648193635, 'when_will': 0.0002903342648193635, 'of_500': 0.0002903342648193635, 'indian_economy': 0.0002903342648193635, 'rs_2000': 0.0002903342648193635, 'will_be': 0.0002854310345957107, 'be_the': 0.0002854310345957107, 'you_think': 0.0002854310345957107, 'and_the': 0.00025913884249135236, 'like_to': 0.0002464351001100554, 'i_improve': 0.0002464351001100554, 'ever_seen': 0.00023527447793040917, 'i_be': 0.00023527447793040917, 'why_has': 0.00023527447793040917}, '0': {'is_a': 0.0004384617607561153, 'the_most': 0.0004322563294194802, 'how_much': 0.000382166813225796, 'should_i': 0.0003802891977723556, 'as_a': 0.00032661664575243005, 'i_have': 0.0003183410564141443, 'what_does': 0.00030453278966008053, 'if_i': 0.0002602086163276493, 'for_a': 0.00021536880394766426, 'start_a': 0.00020464782198052132, 'in_my': 0.00020464782198052132, 'way_to': 0.000200844130037339, 'i_am': 0.00019420487101748994, 'there_a': 0.00016859294607141293, 'how_long': 0.00016859294607141293, 'from_a': 0.00015917052820707214, 'will_i': 0.00015917052820707214, 'and_a': 0.00015917052820707214, 'have_a': 0.00015917052820707214, 'how_many': 0.00015822748235670586, 'i_start': 0.00014615392025203844, 'a_good': 0.00013677029919146184, 'year_old': 0.00013643188132034755, 'it_mean': 0.00013643188132034755, 'to_my': 0.00013643188132034755, 'some_things': 0.00013643188132034755, 'does_my': 0.00013643188132034755, 'long_does': 0.00013643188132034755, 'how_to': 0.00013643188132034755, 'for_the': 0.00012909129102040728, 'how_is': 0.00012909129102040728, 'have_to': 0.00012378418063009505, 'in_2016': 0.00012378418063009505, 'does_it': 0.00011617917595682406, 'to_work': 0.00011369323443362294, 'i_want': 0.00011369323443362294, 'a_startup': 0.00011369323443362294, 'it_normal': 0.00011369323443362294, 'to_see': 0.00011369323443362294, 'most_interesting': 0.00011369323443362294, 'coming_out': 0.00011369323443362294, 'are_good': 0.00011369323443362294, 'for_me': 0.00011369323443362294, 'number_of': 0.00011369323443362294, 'first_day': 0.00011369323443362294, 'mean_when': 0.00011369323443362294, 'it_take': 0.00011369323443362294, 'i_delete': 0.00011369323443362294, 'to_learn': 0.00010768440197383213, 'an_android': 0.00010151092988669349}} \n",
      "\n",
      "n_features: 402\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(docs_train, labels_train)\n",
    "classifier.save(SAVED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'0': 0.93581505376543, '1': 0.06418494623457006},\n",
       " {'0': 0.9199047220951436, '1': 0.08009527790485636}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inferential Examples\n",
    "x = [['Roman Atwood is a content creator .',\n",
    "  'He is best known for his vlogs , where he posts updates about his life on a daily basis .'],\n",
    " ['Roman Atwood is a content creator .',\n",
    "  \"He also has another YouTube channel called `` RomanAtwood '' , where he posts pranks .\"]] \n",
    "classifier.inference(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original train set: 0.695\n",
      "F1-pos on original train set: 0.527\n",
      "F1-neg on original train set: 0.775\n"
     ]
    }
   ],
   "source": [
    "y_preds = classifier.predict(docs_test)\n",
    "\n",
    "print(\"Accuracy on original train set: %.3f\"% accuracy_score(labels_test, y_preds))\n",
    "print(\"F1-pos on original train set: %.3f\"% f1_score(labels_test, y_preds, pos_label='1'))\n",
    "print(\"F1-neg on original train set: %.3f\"% f1_score(labels_test, y_preds, pos_label='0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate load process of the classifier\n",
    "test_classifier = Classifier(\n",
    "    possible_labels=POSSIBLE_LABELS,\n",
    "    feature_extractors=feature_extractors,\n",
    "    config=config\n",
    ")\n",
    "test_classifier.load(SAVED_MODEL_PATH)\n",
    "\n",
    "y_preds = test_classifier.predict(docs_test)\n",
    "\n",
    "print(\"Accuracy on original train set: %.3f\"% accuracy_score(labels_test, y_preds))\n",
    "print(\"F1-pos on original train set: %.3f\"% f1_score(labels_test, y_preds, pos_label='1'))\n",
    "print(\"F1-neg on original train set: %.3f\"% f1_score(labels_test, y_preds, pos_label='0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On original test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples:  200\n"
     ]
    }
   ],
   "source": [
    "eval_docs, eval_labels = read_data(DEV_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original test set: 0.710\n",
      "F1-pos on original test set: 0.554\n",
      "F1-neg on original test set: 0.785\n"
     ]
    }
   ],
   "source": [
    "y_preds = classifier.predict(eval_docs)\n",
    "\n",
    "print(\"Accuracy on original test set: %.3f\"% accuracy_score(eval_labels, y_preds))\n",
    "print(\"F1-pos on original test set: %.3f\"% f1_score(eval_labels, y_preds, pos_label='1'))\n",
    "print(\"F1-neg on original test set: %.3f\"% f1_score(eval_labels, y_preds, pos_label='0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On symmetric (challenge) test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples:  677\n"
     ]
    }
   ],
   "source": [
    "eval_docs, eval_labels = read_data(TEST_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on challenge test set: 0.409\n",
      "F1-pos on challenge test set: 0.419\n",
      "F1-neg on challenge test set: 0.399\n"
     ]
    }
   ],
   "source": [
    "y_preds = classifier.predict(eval_docs)\n",
    "\n",
    "print(\"Accuracy on challenge test set: %.3f\"% accuracy_score(eval_labels, y_preds))\n",
    "print(\"F1-pos on challenge test set: %.3f\"% f1_score(eval_labels, y_preds, pos_label='1'))\n",
    "print(\"F1-neg on challenge test set: %.3f\"% f1_score(eval_labels, y_preds, pos_label='0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write predicted probability to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(prob_score_bias_class: float, ground_truth_label: str, bias_label: str = BIAS_CLASS) -> float:\n",
    "    assert type(ground_truth_label) == type(bias_label)\n",
    "    if ground_truth_label == bias_label:\n",
    "        return 1/prob_score_bias_class\n",
    "    return 1/(1-prob_score_bias_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases\n",
    "def test_bias_label():\n",
    "    weight = get_weight(0.2, \"A\", bias_label=\"A\")\n",
    "    np.testing.assert_almost_equal(1/0.2, weight, 5)\n",
    "    \n",
    "def test_not_bias_label():\n",
    "    weight = get_weight(0.2, \"B\", bias_label=\"A\")\n",
    "    np.testing.assert_almost_equal(1/0.8, weight, 5)\n",
    "    \n",
    "test_bias_label()\n",
    "test_not_bias_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_weight_to_file(\n",
    "    DATA_FILE: str,\n",
    "    OUTPUT_DATA_FILE: str,\n",
    "    _classifier\n",
    ") -> None:\n",
    "    f_output = open(OUTPUT_DATA_FILE, 'w')\n",
    "\n",
    "    N_SAMPLE = 0\n",
    "\n",
    "    with open(DATA_FILE, 'r') as fh:\n",
    "        line = fh.readline()\n",
    "        while line:\n",
    "            datapoint = json.loads(line)\n",
    "            x = [[datapoint[DOC1_KEY], datapoint[DOC2_KEY]]]\n",
    "\n",
    "            probs = _classifier.inference(x)[0]\n",
    "            prob = probs[BIAS_CLASS]\n",
    "            weight = get_weight(\n",
    "                prob_score_bias_class=prob,\n",
    "                ground_truth_label=str(datapoint[LABEL_KEY]),\n",
    "                bias_label=BIAS_CLASS\n",
    "            )\n",
    "            if datapoint.get(\"weight\", None) != None:\n",
    "                del datapoint[\"weight\"] # only for fever\n",
    "            f_output.write(\"%s\\n\"%json.dumps({\n",
    "                **datapoint,\n",
    "                WEIGHT_KEY: weight,\n",
    "                \"bias_probs\": inference_prob_to_index(probs),\n",
    "                \"bias_prob\": prob\n",
    "            }))\n",
    "\n",
    "            N_SAMPLE += 1\n",
    "            if MAX_SAMPLE != -1 and N_SAMPLE == MAX_SAMPLE:\n",
    "                break\n",
    "            line = fh.readline()\n",
    "\n",
    "    f_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_weight_to_file(\n",
    "    DATA_FILE = TRAIN_DATA_FILE,\n",
    "    OUTPUT_DATA_FILE = OUTPUT_TRAIN_DATA_FILE,\n",
    "    _classifier = classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_weight_to_file(\n",
    "    DATA_FILE = VAL_DATA_FILE,\n",
    "    OUTPUT_DATA_FILE = OUTPUT_VAL_DATA_FILe,\n",
    "    _classifier = classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
