{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65a049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63fe30a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>genre</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>pairID</th>\n",
       "      <th>promptID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>government</td>\n",
       "      <td>neutral</td>\n",
       "      <td>31193n</td>\n",
       "      <td>31193</td>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "      <td>( ( Conceptually ( cream skimming ) ) ( ( has ...</td>\n",
       "      <td>(ROOT (S (NP (JJ Conceptually) (NN cream) (NN ...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>( ( ( Product and ) geography ) ( ( are ( what...</td>\n",
       "      <td>(ROOT (S (NP (NN Product) (CC and) (NN geograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[entailment]</td>\n",
       "      <td>telephone</td>\n",
       "      <td>entailment</td>\n",
       "      <td>101457e</td>\n",
       "      <td>101457</td>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "      <td>( you ( ( know ( during ( ( ( the season ) and...</td>\n",
       "      <td>(ROOT (S (NP (PRP you)) (VP (VBP know) (PP (IN...</td>\n",
       "      <td>You lose the things to the following level if ...</td>\n",
       "      <td>( You ( ( ( ( lose ( the things ) ) ( to ( the...</td>\n",
       "      <td>(ROOT (S (NP (PRP You)) (VP (VBP lose) (NP (DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[entailment]</td>\n",
       "      <td>fiction</td>\n",
       "      <td>entailment</td>\n",
       "      <td>134793e</td>\n",
       "      <td>134793</td>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "      <td>( ( One ( of ( our number ) ) ) ( ( will ( ( (...</td>\n",
       "      <td>(ROOT (S (NP (NP (CD One)) (PP (IN of) (NP (PR...</td>\n",
       "      <td>A member of my team will execute your orders w...</td>\n",
       "      <td>( ( ( A member ) ( of ( my team ) ) ) ( ( will...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN member)) (PP (IN o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[entailment]</td>\n",
       "      <td>fiction</td>\n",
       "      <td>entailment</td>\n",
       "      <td>37397e</td>\n",
       "      <td>37397</td>\n",
       "      <td>How do you know? All this is their information...</td>\n",
       "      <td>( ( How ( ( ( do you ) know ) ? ) ) ( ( All th...</td>\n",
       "      <td>(ROOT (S (SBARQ (WHADVP (WRB How)) (SQ (VBP do...</td>\n",
       "      <td>This information belongs to them.</td>\n",
       "      <td>( ( This information ) ( ( belongs ( to them )...</td>\n",
       "      <td>(ROOT (S (NP (DT This) (NN information)) (VP (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>telephone</td>\n",
       "      <td>neutral</td>\n",
       "      <td>50563n</td>\n",
       "      <td>50563</td>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "      <td>( yeah ( i ( ( tell you ) ( what ( ( though ( ...</td>\n",
       "      <td>(ROOT (S (VP (VB yeah) (S (NP (FW i)) (VP (VB ...</td>\n",
       "      <td>The tennis shoes have a range of prices.</td>\n",
       "      <td>( ( The ( tennis shoes ) ) ( ( have ( ( a rang...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN tennis) (NNS shoes))...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotator_labels       genre  gold_label   pairID  promptID  \\\n",
       "0        [neutral]  government     neutral   31193n     31193   \n",
       "1     [entailment]   telephone  entailment  101457e    101457   \n",
       "2     [entailment]     fiction  entailment  134793e    134793   \n",
       "3     [entailment]     fiction  entailment   37397e     37397   \n",
       "4        [neutral]   telephone     neutral   50563n     50563   \n",
       "\n",
       "                                           sentence1  \\\n",
       "0  Conceptually cream skimming has two basic dime...   \n",
       "1  you know during the season and i guess at at y...   \n",
       "2  One of our number will carry out your instruct...   \n",
       "3  How do you know? All this is their information...   \n",
       "4  yeah i tell you what though if you go price so...   \n",
       "\n",
       "                              sentence1_binary_parse  \\\n",
       "0  ( ( Conceptually ( cream skimming ) ) ( ( has ...   \n",
       "1  ( you ( ( know ( during ( ( ( the season ) and...   \n",
       "2  ( ( One ( of ( our number ) ) ) ( ( will ( ( (...   \n",
       "3  ( ( How ( ( ( do you ) know ) ? ) ) ( ( All th...   \n",
       "4  ( yeah ( i ( ( tell you ) ( what ( ( though ( ...   \n",
       "\n",
       "                                     sentence1_parse  \\\n",
       "0  (ROOT (S (NP (JJ Conceptually) (NN cream) (NN ...   \n",
       "1  (ROOT (S (NP (PRP you)) (VP (VBP know) (PP (IN...   \n",
       "2  (ROOT (S (NP (NP (CD One)) (PP (IN of) (NP (PR...   \n",
       "3  (ROOT (S (SBARQ (WHADVP (WRB How)) (SQ (VBP do...   \n",
       "4  (ROOT (S (VP (VB yeah) (S (NP (FW i)) (VP (VB ...   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  Product and geography are what make cream skim...   \n",
       "1  You lose the things to the following level if ...   \n",
       "2  A member of my team will execute your orders w...   \n",
       "3                  This information belongs to them.   \n",
       "4           The tennis shoes have a range of prices.   \n",
       "\n",
       "                              sentence2_binary_parse  \\\n",
       "0  ( ( ( Product and ) geography ) ( ( are ( what...   \n",
       "1  ( You ( ( ( ( lose ( the things ) ) ( to ( the...   \n",
       "2  ( ( ( A member ) ( of ( my team ) ) ) ( ( will...   \n",
       "3  ( ( This information ) ( ( belongs ( to them )...   \n",
       "4  ( ( The ( tennis shoes ) ) ( ( have ( ( a rang...   \n",
       "\n",
       "                                     sentence2_parse  \n",
       "0  (ROOT (S (NP (NN Product) (CC and) (NN geograp...  \n",
       "1  (ROOT (S (NP (PRP You)) (VP (VBP lose) (NP (DT...  \n",
       "2  (ROOT (S (NP (NP (DT A) (NN member)) (PP (IN o...  \n",
       "3  (ROOT (S (NP (DT This) (NN information)) (VP (...  \n",
       "4  (ROOT (S (NP (DT The) (NN tennis) (NNS shoes))...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"../data/nli/multinli_1.0_train.jsonl\", lines=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a57d94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b53c0",
   "metadata": {},
   "source": [
    "# bart-large-mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9106adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\", num_labels=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deedee10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3374023f96c40b4afe1ddfabcee170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mnli/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "logits = []\n",
    "probs = []\n",
    "for idx, row in tqdm(data.iterrows()):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer.encode_plus(row[\"sentence1\"], row[\"sentence2\"], \n",
    "                                       add_special_tokens=True,\n",
    "                                       return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "    probs.append(F.softmax(outputs.logits)[0].to(\"cpu\"))\n",
    "    logits.append(outputs.logits[0].tolist())\n",
    "    del inputs, outputs\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ebeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"logits\"] = logits\n",
    "for i in range(len(probs)):\n",
    "    probs[i] = probs[i].tolist()\n",
    "data[\"probs\"] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction indexes for each model may vary\n",
    "for i in tqdm(range(len(data))):\n",
    "    logits = []\n",
    "    probs = []\n",
    "    logits.append(data[i]['logits'][0][2])\n",
    "    logits.append(data[i]['logits'][0][0])\n",
    "    logits.append(data[i]['logits'][0][1])\n",
    "    probs.append(data[i]['probs'][0][2])\n",
    "    probs.append(data[i]['probs'][0][0])\n",
    "    probs.append(data[i]['probs'][0][1])\n",
    "    data[i]['logits'] = logits\n",
    "    data[i]['probs'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81847c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eacaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = data.to_json(orient='records', lines=True)\n",
    "with open(\"bart-large-mnli-predicted.jsonl\", 'w') as f:\n",
    "    f.write(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be35cf",
   "metadata": {},
   "source": [
    "# roberta-large-mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\", num_labels=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb925ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = []\n",
    "probs = []\n",
    "for idx, row in tqdm(data.iterrows()):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer.encode_plus(row[\"sentence1\"], row[\"sentence2\"], \n",
    "                                       add_special_tokens=True,\n",
    "                                       return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "    probs.append(F.softmax(outputs.logits)[0].to(\"cpu\"))\n",
    "    logits.append(outputs.logits[0].tolist())\n",
    "    del inputs, outputs\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"logits\"] = logits\n",
    "for i in range(len(probs)):\n",
    "    probs[i] = probs[i].tolist()\n",
    "data[\"probs\"] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dfdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction indexes for each model may vary\n",
    "for i in tqdm(range(len(data))):\n",
    "    logits = []\n",
    "    probs = []\n",
    "    logits.append(data[i]['logits'][0][2])\n",
    "    logits.append(data[i]['logits'][0][0])\n",
    "    logits.append(data[i]['logits'][0][1])\n",
    "    probs.append(data[i]['probs'][0][2])\n",
    "    probs.append(data[i]['probs'][0][0])\n",
    "    probs.append(data[i]['probs'][0][1])\n",
    "    data[i]['logits'] = logits\n",
    "    data[i]['probs'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = data.to_json(orient='records', lines=True)\n",
    "with open(\"roberta-large-mnli-predicted.jsonl\", 'w') as f:\n",
    "    f.write(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24088d4",
   "metadata": {},
   "source": [
    "# bert-base-mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9af176",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ishan/bert-base-uncased-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ishan/bert-base-uncased-mnli\", num_labels=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = []\n",
    "probs = []\n",
    "for idx, row in tqdm(data.iterrows()):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer.encode_plus(row[\"sentence1\"], row[\"sentence2\"], \n",
    "                                       add_special_tokens=True,\n",
    "                                       return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "    probs.append(F.softmax(outputs.logits)[0].to(\"cpu\"))\n",
    "    logits.append(outputs.logits[0].tolist())\n",
    "    del inputs, outputs\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"logits\"] = logits\n",
    "for i in range(len(probs)):\n",
    "    probs[i] = probs[i].tolist()\n",
    "data[\"probs\"] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction indexes for each model may vary\n",
    "for i in tqdm(range(len(data))):\n",
    "    logits = []\n",
    "    probs = []\n",
    "    logits.append(data[i]['logits'][1])\n",
    "    logits.append(data[i]['logits'][0])\n",
    "    logits.append(data[i]['logits'][2])\n",
    "    probs.append(data[i]['probs'][1])\n",
    "    probs.append(data[i]['probs'][0])\n",
    "    probs.append(data[i]['probs'][2])\n",
    "    data[i]['logits'] = logits\n",
    "    data[i]['probs'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = data.to_json(orient='records', lines=True)\n",
    "with open(\"bert-base-mnli-predicted.jsonl\", 'w') as f:\n",
    "    f.write(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
