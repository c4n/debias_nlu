{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import glob\n",
    "import os\n",
    "import fuse, causal_utils\n",
    "glob.glob(\"/ist/ist-share/scads/can/robust_nlu/korn_reweight/nli/*/\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/ist/ist-share/scads/can/robust_nlu/korn_reweight/nli/outputs_bert_base_overlapping_korn_ps3class_3/',\n",
       " '/ist/ist-share/scads/can/robust_nlu/korn_reweight/nli/outputs_bert_base_overlapping_korn_ps3class_2/',\n",
       " '/ist/ist-share/scads/can/robust_nlu/korn_reweight/nli/outputs_bert_base_overlapping_korn_ps3class_1/']"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "!ls /raid/can/nli_models/baseline_mind_distill/nli/seed1/"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best.th\t\t      model_state_e2_b0.th  raw_train.jsonl\r\n",
      "config.json\t      model_state_e3_b0.th  temperature.pt\r\n",
      "meta.json\t      model.tar.gz\t    training_state_e2_b0.th\r\n",
      "metrics_epoch_0.json  normal\t\t    training_state_e3_b0.th\r\n",
      "metrics_epoch_1.json  out.log\t\t    vocabulary\r\n",
      "metrics_epoch_2.json  raw_m.jsonl\r\n",
      "metrics.json\t      raw_mm.jsonl\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "\n",
    "# select model\n",
    "model_path='/raid/can/nli_models/baseline_mind_distill/nli/seed1/'\n",
    "# select data path\n",
    "data_path='/ist/users/canu/debias_nlu/data/nli/'\n",
    "df = pd.read_json(model_path+'raw_train.jsonl', lines=True)\n",
    "# select fusion method here\n",
    "fusion = fuse.sum_fuse"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  get score from the bias model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# avg prob\n",
    "#s score from bias model\n",
    "df_hans = pd.read_json(data_path+'hans_prob_korn_lr_overlapping_sample_weight_3class.jsonl', lines=True)\n",
    "hans_score=[b for b in df_hans['bias_probs'] ]\n",
    "hans_score=np.array(hans_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get avg  prob of bert"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "list_probs = []\n",
    "for i in df['probs']:\n",
    "    list_probs.extend(i)\n",
    "x=np.array(list_probs)\n",
    "avg=np.average(x,axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "avg"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.29599526, 0.34789062, 0.35611412])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# y1m0"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "bias_score=fusion(avg,hans_score)\n",
    "#y1m0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "bias_score[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.3057925 , -0.46523137, -0.49389628])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "result_path=model_path+'normal/'\n",
    "# bert model predictions on HANS\n",
    "df_bert = pd.read_json(result_path+'hans_result.jsonl', lines=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# ent = []\n",
    "y1m1prob = []\n",
    "for p,h in zip(df_bert['probs'],hans_score):\n",
    "    new_y1m1 = fusion(np.array(p),h)\n",
    "    y1m1prob.append(new_y1m1)\n",
    "  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "labels[14000]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'non-entailment'"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# corrected y1m0"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "c = sharpness_correction(hans_score, y1m1prob) \n",
    "bias_score = fusion(c,hans_score)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'sharpness_correction' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1104190/3371130559.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msharpness_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhans_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1m1prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbias_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhans_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sharpness_correction' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TIE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "debias_scores = []\n",
    "for p,b in zip(y1m1prob,bias_score):\n",
    "    debias_scores.append(p-b) # TIE  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Eval HANS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "key = {0:\"entailment\",1:\"contradiction\",2:\"neutral\"}\n",
    "labels = []\n",
    "for i in debias_scores:\n",
    "    labels.append(key[np.argmax(i)])\n",
    "df_bert['debias_label']=labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "text_ans=\"\"\n",
    "for idx, obj in enumerate(df_bert['label']):\n",
    "    text_ans = text_ans + \"ex\"+str(idx)+\",\"+obj+\"\\n\"   \n",
    "    \n",
    "text_ans_debias=\"\"\n",
    "for idx, obj in enumerate(df_bert['debias_label']):\n",
    "    text_ans_debias = text_ans_debias + \"ex\"+str(idx)+\",\"+obj+\"\\n\"          "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "def format_label(label):\n",
    "    if label == \"entailment\":\n",
    "        return \"entailment\"\n",
    "    else:\n",
    "        return \"non-entailment\"\n",
    "\n",
    "guess_dict = {}\n",
    "for line in text_ans.split(\"\\n\"):\n",
    "    if len(line)>1:\n",
    "        parts = line.strip().split(\",\")\n",
    "        guess_dict[parts[0]] = format_label(parts[1])\n",
    "        \n",
    "guess_dict_debias = {}\n",
    "for line in text_ans_debias.split(\"\\n\"):\n",
    "    if len(line)>1:\n",
    "        parts = line.strip().split(\",\")\n",
    "        guess_dict_debias[parts[0]] = format_label(parts[1])        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "labels,baseline_avg=causal_utils.get_heur(guess_dict) # normal"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9634\n",
      "subsequence: 0.9958\n",
      "constituent: 0.9982\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.6628\n",
      "subsequence: 0.1176\n",
      "constituent: 0.2214\n",
      "avg: 0.6598666666666666\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "labels,debias_avg=causal_utils.get_heur(guess_dict_debias) # TIE"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9644\n",
      "subsequence: 0.9962\n",
      "constituent: 0.9986\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.6568\n",
      "subsequence: 0.108\n",
      "constituent: 0.185\n",
      "avg: 0.6515000000000001\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Causal Mediation Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "def get_ans(ans):\n",
    "    if ans == 0:\n",
    "        return 'entailment'\n",
    "    else:\n",
    "        return 'non-entailment' \n",
    "    \n",
    "# y0m0\n",
    "import pickle\n",
    "modelname='mnli_lr_model.sav'\n",
    "loaded_model = pickle.load(open(modelname, 'rb'))\n",
    "x0=loaded_model.predict_proba(np.array([[0,0,0.41997876976119086]]))\n",
    "m0=avg\n",
    "y0m0=fusion(x0,m0)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "factual_pred_correct = []\n",
    "TIE_pred_correct = []\n",
    "NIE_pred_correct = []\n",
    "INTmed_pred_correct = []\n",
    "pred_correct = []\n",
    "all_TIE = []\n",
    "all_NIE = []\n",
    "all_NDE = []\n",
    "all_INTmed = []\n",
    "for i in range(len(labels)): \n",
    "    y1m1 = y1m1prob[i]\n",
    "    y1m0 = bias_score[i]\n",
    "    TE = y1m1 - y0m0\n",
    "    NDE = bias_score[i] - y0m0\n",
    "    y0m1= fusion(x0,np.array(df_bert['probs'][i]) )\n",
    "    TIE = y1m1 - y1m0\n",
    "    NIE = y0m1 - y0m0\n",
    "    INTmed = TIE - NIE\n",
    "    # factual\n",
    "    factual_ans = np.argmax(df_bert['probs'][i])\n",
    "    factual_ans = get_ans(factual_ans)\n",
    "    factual_correct = factual_ans==labels[i]   \n",
    "    factual_pred_correct.append(factual_correct)\n",
    "    # TIE\n",
    "    TIE_ans = np.argmax(TIE)\n",
    "    TIE_ans = get_ans(TIE_ans)\n",
    "    TIE_correct = TIE_ans==labels[i]  \n",
    "    TIE_pred_correct.append(TIE_correct)\n",
    "    # INTmed\n",
    "    INTmed_ans = np.argmax(INTmed[0])\n",
    "    INTmed_ans = get_ans(INTmed_ans)\n",
    "    INTmed_correct = INTmed_ans==labels[i]  \n",
    "    INTmed_pred_correct.append(INTmed_correct)\n",
    "    # NIE\n",
    "    NIE_ans = np.argmax(NIE[0])\n",
    "    NIE_ans = get_ans(NIE_ans)\n",
    "    NIE_correct = NIE_ans==labels[i]  \n",
    "    NIE_pred_correct.append(NIE_correct)    \n",
    "    \n",
    "    # save\n",
    "    all_NDE.append(NDE[0][0])\n",
    "    all_NIE.append(NIE[0][0])\n",
    "    all_TIE.append(TIE[0])\n",
    "    all_INTmed.append((INTmed[0][0]))\n",
    "    if  (TIE[0]/TE[0][0])<9999999:\n",
    "        cf_ans = np.argmax(np.array(df_bert['probs'][i]-hans_score[i]))\n",
    "        cf_ans = get_ans(cf_ans)\n",
    "        cf_correct = cf_ans==labels[i]\n",
    "    else:\n",
    "#         print(cf_ans)\n",
    "        cf_correct = factual_ans ==labels[i]\n",
    "    pred_correct.append(cf_correct)\n",
    "    \n",
    "#     np.array(df_bert['probs'][i]-bias_score)\n",
    "#     labels[i]\n",
    "print(np.array(all_TIE).mean(),(np.array(all_TIE).std()))\n",
    "print(np.array(all_INTmed).mean(),(np.array(all_INTmed).std()))\n",
    "print(np.array(all_NIE).mean(),(np.array(all_NIE).std()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.05897773440853179 0.04002435525754341\n",
      "-0.02051590710053735 0.013665625425377402\n",
      "0.07949364150906912 0.05368544027567681\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "np.array(df_bert['probs'][i]-hans_score[i])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.06199987, -0.03410642,  0.09610631])"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "df_bert['probs'][i]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6700639724731441, 0.141605570912361, 0.18833048641681602]"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "hans_score[i]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.73206384, 0.17571199, 0.09222417])"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "print(sum(NIE_pred_correct)/30000,sum(INTmed_pred_correct)/30000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6439333333333334 0.4606\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "print(sum(factual_pred_correct)/30000,sum(pred_correct)/30000,sum(TIE_pred_correct)/30000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6598666666666667 0.5182 0.6515\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#TIE # 0.032416620996870094 # utama best seed  0.04260506151060745\n",
    "#TIE # 0.0879242620437139 # PoE\n",
    "#TIE # 0.10864416858494 # Baseline 0.10295758381662952\n",
    "#\n",
    "# baseline\n",
    "# reweight_korn\n",
    "# poe_korn\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "!ls /raid/can/nli_models/"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "baseline\t       check_baseline  poe   poe3\r\n",
      "baseline_mind_distill  korn_reweight   poe2  reweight_utama_github\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "!python cma.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "import cma\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import fuse, causal_utils\n",
    "model_path='/raid/can/nli_models/baseline_mind_distill/'\n",
    "task='nli'\n",
    "data_path='/ist/users/canu/debias_nlu/data/' + task + '/'\n",
    "fusion = fuse.sum_fuse\n",
    "test_set='hans'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "cma.report_CMA(model_path,task,data_path,test_set,fusion)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/raid/can/nli_models/baseline_mind_distill/nli/seed3/normal/\n",
      "0.05672240423200177 0.04367789158020039\n",
      "-0.019779908793118497 0.014807252886696553\n",
      "0.07650231302512027 0.05848018108650776\n",
      "/raid/can/nli_models/baseline_mind_distill/nli/seed2/normal/\n",
      "0.052288068563398654 0.04736277649260647\n",
      "-0.018279927934217562 0.015949873664305683\n",
      "0.0705679964976162 0.06330753909230802\n",
      "/raid/can/nli_models/baseline_mind_distill/nli/seed1/normal/\n",
      "0.05897773440853179 0.04002435525754341\n",
      "-0.02051590710053735 0.013665625425377402\n",
      "0.07949364150906912 0.05368544027567681\n",
      "factual score:\n",
      "[0.66, 0.6872, 0.6598666666666667] 0.6690222222222223 0.012853745190881088\n",
      "TE:\n",
      "[0.18167084138284345, 0.17734217041887054, 0.18387677539931505] 0.180963262400343 0.0027142545416092663\n",
      "TIE:\n",
      "[0.05672240423200177, 0.052288068563398654, 0.05897773440853179] 0.055996069067977404 0.002778918177727792\n",
      "[0.6533666666666667, 0.6796666666666666, 0.6515] 0.661511111111111 0.012860514744992628\n",
      "NIE:\n",
      "[0.07650231302512027, 0.0705679964976162, 0.07949364150906912] 0.07552131701060187 0.0037093170622990545\n",
      "[0.6488333333333334, 0.6751666666666667, 0.6439333333333334] 0.6559777777777778 0.013715261392395274\n",
      "INTmed:\n",
      "[-0.019779908793118497, -0.018279927934217562, -0.02051590710053735] -0.01952524794262447 0.0009304263609173263\n",
      "[0.43373333333333336, 0.4020666666666667, 0.4606] 0.4321333333333334 0.023922900852220767\n",
      "my query:\n",
      "[0.5133666666666666, 0.5118666666666667, 0.5182] 0.5144777777777778 0.0027023081126700617\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "df_bert = pd.read_json('/raid/can/nli_models/poe3/nli/outputs_poe_bert_base_korn_clark_1_seed13370/'+'raw_mm.jsonl', lines=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "!ls /raid/can/nli_models/"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "baseline  check_baseline  korn_reweight  poe  poe2  poe3  reweight_utama_github\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "!ls -ltr /raid/can/nli_models/baseline/nli/outputs_bert_base_clark_1_seed13370/normal/\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total 2406868\r\n",
      "-rw-rw-r-- 1 canu canu        66 Nov 30 13:43 spelling_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        66 Nov 30 13:43 negation_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        66 Nov 30 13:43 numerical_reasoning_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        66 Nov 30 13:43 length_mismatch_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        65 Nov 30 13:43 antonym_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        66 Nov 30 13:43 word_overlap_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu 193014347 Dec  1 00:08 distill_output_1.jsonl\r\n",
      "drwxrwxr-x 3 canu canu      4096 Dec  1 01:07 distill_model_1\r\n",
      "-rw-rw-r-- 1 canu canu 615717404 Dec  1 05:01 raw_train_result_2.jsonl\r\n",
      "drwxrwxr-x 4 canu canu      4096 Dec  2 00:10 distill_model_0\r\n",
      "-rw-rw-r-- 1 canu canu 193128135 Dec  2 04:52 distill_output_0.jsonl\r\n",
      "-rw-rw-r-- 1 canu canu        67 Dec  7 22:36 result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        66 Dec  7 22:36 snli_hard_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        66 Dec  7 22:36 mnli_hard_dev_mm_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        52 Dec  7 22:36 kaushik_rp_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        53 Dec  7 22:36 kaushik_rh_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu        54 Dec  7 22:36 kaushik_combined_result.txt\r\n",
      "-rw-rw-r-- 1 canu canu  14304241 Dec  7 22:45 hans_result.jsonl\r\n",
      "-rw-rw-r-- 1 canu canu    569072 Dec  7 22:45 hans.out\r\n",
      "-rw-rw-r-- 1 canu canu      2140 Dec  7 22:45 hans_results.txt\r\n",
      "-rw-rw-r-- 1 canu canu    349018 Dec  7 22:45 hans.p\r\n",
      "-rw-rw-r-- 1 canu canu        67 Dec  7 23:03 result_train.txt\r\n",
      "-rw-rw-r-- 1 canu canu 615891867 Dec 14 21:51 raw_train_result_0.jsonl\r\n",
      "-rw-rw-r-- 1 canu canu 615814916 Dec 15 01:35 raw_train_result_1.jsonl\r\n",
      "-rw-rw-r-- 1 canu canu 215743993 Dec 15 14:00 utama_distill_output_0.jsonl\r\n",
      "drwxrwxr-x 3 canu canu      4096 Dec 15 14:08 utama_distill_model_0\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "  df_bias_model = pd.read_json(data_path+'test'+'_prob_korn_lr_overlapping_sample_weight_3class.jsonl', lines=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "if '-' in df_bias_model['gold_label'].value_counts():\n",
    "    print(df_bias_model['gold_label'].value_counts()['-'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "168\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df_bias_model"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_bias_model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3679248/3595450433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_bias_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_bias_model' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "print('Gradient function for z =', z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x7fa37bdb2490>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fa37bdb26a0>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.1463, 0.1088, 0.0836],\n",
      "        [0.1463, 0.1088, 0.0836],\n",
      "        [0.1463, 0.1088, 0.0836],\n",
      "        [0.1463, 0.1088, 0.0836],\n",
      "        [0.1463, 0.1088, 0.0836]])\n",
      "tensor([0.1463, 0.1088, 0.0836])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1104190/467591778.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, probs,target_probs):\n",
    "        self.probs  = torch.tensor(probs)\n",
    "        self.target_probs = torch.tensor(target_probs)\n",
    "    def __len__(self):\n",
    "        return len(self.probs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.probs[idx], self.target_probs[idx]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "df_bert['probs'][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.13495792448520602, 0.7968678474426271, 0.068174198269844]"
      ]
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "train=CustomImageDataset(df_bert['probs'],df_bert['probs'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "class TempScale(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TempScale, self).__init__()\n",
    "        self.T = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x/self.T)/torch.sum(x/self.T)\n",
    "        return x\n",
    "model = TempScale()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = dataloader.__len__()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "train_loop(train, model, loss_fn, optimizer)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1104190/3438439461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1104190/2134211393.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CI_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CI_env/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m~/CI_env/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "train.__len__()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "torch.tensor(df_bert['probs']).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([30000, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}