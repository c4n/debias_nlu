{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "619e5d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ist/ist-share/scads/can/robust_nlu/korn_reweight/nli/outputs_bert_base_overlapping_korn_ps3class_3/',\n",
       " '/ist/ist-share/scads/can/robust_nlu/korn_reweight/nli/outputs_bert_base_overlapping_korn_ps3class_2/',\n",
       " '/ist/ist-share/scads/can/robust_nlu/korn_reweight/nli/outputs_bert_base_overlapping_korn_ps3class_1/']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import fuse, causal_utils\n",
    "glob.glob(\"/ist/ist-share/scads/can/robust_nlu/korn_reweight/nli/*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f4f414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nli  outputs_poe_bert_base_korn_clark_1_seed33370\r\n"
     ]
    }
   ],
   "source": [
    "!ls /raid/can/nli_models/poe3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3ca15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "\n",
    "# select model\n",
    "model_path='/raid/can/nli_models/poe3/nli/outputs_poe_bert_base_korn_clark_1_seed13370/'\n",
    "# select data path\n",
    "data_path='/ist/users/canu/debias_nlu/data/nli/'\n",
    "df = pd.read_json(model_path+'raw_train.jsonl', lines=True)\n",
    "# select fusion method here\n",
    "fusion = fuse.sum_fuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb111eb4",
   "metadata": {},
   "source": [
    "#  get score from the bias model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c1fb006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg prob\n",
    "#s score from bias model\n",
    "df_hans = pd.read_json(data_path+'hans_prob_korn_lr_overlapping_sample_weight_3class.jsonl', lines=True)\n",
    "hans_score=[b for b in df_hans['bias_probs'] ]\n",
    "hans_score=np.array(hans_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40467551",
   "metadata": {},
   "source": [
    "# Get avg  prob of bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76b50e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_probs = []\n",
    "for i in df['probs']:\n",
    "    list_probs.extend(i)\n",
    "x=np.array(list_probs)\n",
    "avg=np.average(x,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3dd3c",
   "metadata": {},
   "source": [
    "# y0m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940194d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_score=fusion(avg,hans_score)\n",
    "#y0m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fe016b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/raid/can/nli_models/poe3/outputs_poe_bert_base_korn_clark_1_seed13370/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /raid/can/nli_models/poe3/outputs_poe_bert_base_korn_clark_1_seed13370/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "087e608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path=model_path+'normal/'\n",
    "df_bert = pd.read_json(result_path+'hans_result.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0b3c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ent = []\n",
    "y1m1prob = []\n",
    "for p,h in zip(df_bert['probs'],hans_score):\n",
    "    new_y1m1 = fusion(np.array(p),h)\n",
    "    y1m1prob.append(new_y1m1)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8175e2",
   "metadata": {},
   "source": [
    "# corrected y0m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9d46834",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sharpness_correction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3153201/3371130559.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msharpness_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhans_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1m1prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbias_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhans_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sharpness_correction' is not defined"
     ]
    }
   ],
   "source": [
    "c = sharpness_correction(hans_score, y1m1prob) \n",
    "bias_score = fusion(c,hans_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddfb2e",
   "metadata": {},
   "source": [
    "# TIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca00c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_scores = []\n",
    "for p,b in zip(y1m1prob,bias_score):\n",
    "    debias_scores.append(p-b) # TIE  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4220f3",
   "metadata": {},
   "source": [
    "# Eval HANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f63e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {0:\"entailment\",1:\"contradiction\",2:\"neutral\"}\n",
    "labels = []\n",
    "for i in debias_scores:\n",
    "    labels.append(key[np.argmax(i)])\n",
    "df_bert['debias_label']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e845f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ans=\"\"\n",
    "for idx, obj in enumerate(df_bert['label']):\n",
    "    text_ans = text_ans + \"ex\"+str(idx)+\",\"+obj+\"\\n\"   \n",
    "    \n",
    "text_ans_debias=\"\"\n",
    "for idx, obj in enumerate(df_bert['debias_label']):\n",
    "    text_ans_debias = text_ans_debias + \"ex\"+str(idx)+\",\"+obj+\"\\n\"          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d416a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_label(label):\n",
    "    if label == \"entailment\":\n",
    "        return \"entailment\"\n",
    "    else:\n",
    "        return \"non-entailment\"\n",
    "\n",
    "guess_dict = {}\n",
    "for line in text_ans.split(\"\\n\"):\n",
    "    if len(line)>1:\n",
    "        parts = line.strip().split(\",\")\n",
    "        guess_dict[parts[0]] = format_label(parts[1])\n",
    "        \n",
    "guess_dict_debias = {}\n",
    "for line in text_ans_debias.split(\"\\n\"):\n",
    "    if len(line)>1:\n",
    "        parts = line.strip().split(\",\")\n",
    "        guess_dict_debias[parts[0]] = format_label(parts[1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ba67756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9734\n",
      "subsequence: 0.9968\n",
      "constituent: 0.9924\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.7482\n",
      "subsequence: 0.1114\n",
      "constituent: 0.3026\n",
      "avg: 0.6874666666666668\n"
     ]
    }
   ],
   "source": [
    "labels,baseline_avg=causal_utils.get_heur(guess_dict) # normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af032637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9724\n",
      "subsequence: 0.9966\n",
      "constituent: 0.9912\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.7528\n",
      "subsequence: 0.116\n",
      "constituent: 0.3132\n",
      "avg: 0.6903666666666667\n"
     ]
    }
   ],
   "source": [
    "labels,debias_avg=causal_utils.get_heur(guess_dict_debias) # TIE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56bd53",
   "metadata": {},
   "source": [
    "# Causal Mediation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75c54f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ans(ans):\n",
    "    if ans == 0:\n",
    "        return 'entailment'\n",
    "    else:\n",
    "        return 'non-entailment' \n",
    "    \n",
    "# y0m0\n",
    "import pickle\n",
    "modelname='mnli_lr_model.sav'\n",
    "loaded_model = pickle.load(open(modelname, 'rb'))\n",
    "x0=loaded_model.predict_proba(np.array([[0,0,0.41997876976119086]]))\n",
    "m0=avg\n",
    "y0m0=fusion(x0,m0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34db22d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08649503037239671 0.07753374427816435\n",
      "-0.03193751895445736 0.026914285032747287\n",
      "0.11843254932685407 0.10443938146612336\n"
     ]
    }
   ],
   "source": [
    "factual_pred_correct = []\n",
    "TIE_pred_correct = []\n",
    "NIE_pred_correct = []\n",
    "INTmed_pred_correct = []\n",
    "pred_correct = []\n",
    "all_TIE = []\n",
    "all_NIE = []\n",
    "all_NDE = []\n",
    "all_INTmed = []\n",
    "for i in range(len(labels)): \n",
    "    y1m1 = y1m1prob[i]\n",
    "    y1m0 = bias_score[i]\n",
    "    TE = y1m1 - y0m0\n",
    "    NDE = bias_score[i] - y0m0\n",
    "    y0m1= fusion(x0,np.array(df_bert['probs'][i]) )\n",
    "    TIE = y1m1 - y1m0\n",
    "    NIE = y0m1 - y0m0\n",
    "    INTmed = TIE - NIE\n",
    "    # factual\n",
    "    factual_ans = np.argmax(df_bert['probs'][i])\n",
    "    factual_ans = get_ans(factual_ans)\n",
    "    factual_correct = factual_ans==labels[i]   \n",
    "    factual_pred_correct.append(factual_correct)\n",
    "    # TIE\n",
    "    TIE_ans = np.argmax(TIE)\n",
    "    TIE_ans = get_ans(TIE_ans)\n",
    "    TIE_correct = TIE_ans==labels[i]  \n",
    "    TIE_pred_correct.append(TIE_correct)\n",
    "    # INTmed\n",
    "    INTmed_ans = np.argmax(INTmed[0])\n",
    "    INTmed_ans = get_ans(INTmed_ans)\n",
    "    INTmed_correct = INTmed_ans==labels[i]  \n",
    "    INTmed_pred_correct.append(INTmed_correct)\n",
    "    # NIE\n",
    "    NIE_ans = np.argmax(NIE[0])\n",
    "    NIE_ans = get_ans(NIE_ans)\n",
    "    NIE_correct = NIE_ans==labels[i]  \n",
    "    NIE_pred_correct.append(NIE_correct)    \n",
    "    \n",
    "    # save\n",
    "    all_NDE.append(NDE[0][0])\n",
    "    all_NIE.append(NIE[0][0])\n",
    "    all_TIE.append(TIE[0])\n",
    "    all_INTmed.append((INTmed[0][0]))\n",
    "    if  (TIE[0]/TE[0][0])<9999999:\n",
    "        cf_ans = np.argmax(np.array(df_bert['probs'][i]-hans_score[i]))\n",
    "        cf_ans = get_ans(cf_ans)  \n",
    "        cf_correct = cf_ans==labels[i]\n",
    "    else:\n",
    "#         print(cf_ans)\n",
    "        cf_correct = factual_ans ==labels[i]\n",
    "    pred_correct.append(cf_correct)\n",
    "    \n",
    "#     np.array(df_bert['probs'][i]-bias_score)\n",
    "#     labels[i]\n",
    "print(np.array(all_TIE).mean(),(np.array(all_TIE).std()))\n",
    "print(np.array(all_INTmed).mean(),(np.array(all_INTmed).std()))\n",
    "print(np.array(all_NIE).mean(),(np.array(all_NIE).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0548cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.argmax(NIE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a32e584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18147684, -0.12462973, -0.12555245]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "138083cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6872666666666667 0.3651\n"
     ]
    }
   ],
   "source": [
    "print(sum(NIE_pred_correct)/30000,sum(INTmed_pred_correct)/30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28f22fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6874666666666667 0.7312 0.6903666666666667\n"
     ]
    }
   ],
   "source": [
    "print(sum(factual_pred_correct)/30000,sum(pred_correct)/30000,sum(TIE_pred_correct)/30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01ad2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIE # 0.032416620996870094 # utama best seed  0.04260506151060745\n",
    "#TIE # 0.0879242620437139 # PoE\n",
    "#TIE # 0.10864416858494 # Baseline 0.10295758381662952\n",
    "#\n",
    "# baseline\n",
    "# reweight_korn\n",
    "# poe_korn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02116866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9838\n",
      "subsequence: 0.9946\n",
      "constituent: 0.9978\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.7264\n",
      "subsequence: 0.1144\n",
      "constituent: 0.2728\n",
      "avg: 0.6816333333333334\n",
      "0.09049318935295611 0.07330273608231962\n",
      "-0.033259518297814955 0.025551918800548676\n",
      "0.12375270765077105 0.09884589944548612\n",
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9784\n",
      "subsequence: 0.9986\n",
      "constituent: 0.9998\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.6494\n",
      "subsequence: 0.0844\n",
      "constituent: 0.1872\n",
      "avg: 0.6496333333333333\n",
      "0.09638890603753264 0.06965581836013897\n",
      "-0.035384280694031746 0.024282320036851667\n",
      "0.13177318673156438 0.09392968074471238\n",
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9756\n",
      "subsequence: 0.9966\n",
      "constituent: 0.9952\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.7424\n",
      "subsequence: 0.1658\n",
      "constituent: 0.285\n",
      "avg: 0.6934333333333332\n",
      "0.0880008136703304 0.07883599964955158\n",
      "-0.03250504798919367 0.027354145127177664\n",
      "0.1205058616595241 0.10618183988554827\n",
      "TE:\n",
      "[0.2125167564372472, 0.21823456620890513, 0.21015405162657436] 0.21363512475757554 0.003392318750132485\n",
      "TIE:\n",
      "[0.09049318935295611, 0.09638890603753264, 0.0880008136703304] 0.09162763635360638 0.003517124856862721\n",
      "[0.6849333333333333, 0.6529333333333334, 0.6961333333333334] 0.678 0.018305069121845877\n",
      "NIE:\n",
      "[0.12375270765077105, 0.13177318673156438, 0.1205058616595241] 0.12534391868061984 0.00473547730617103\n",
      "[0.6806, 0.6493, 0.6926] 0.6741666666666667 0.018253097149677246\n",
      "INTmed:\n",
      "[-0.033259518297814955, -0.035384280694031746, -0.03250504798919367] -0.03371628232701345 0.0012190078687002084\n",
      "[0.38803333333333334, 0.4032, 0.36623333333333336] 0.38582222222222223 0.015172351396984583\n",
      "my query:\n",
      "[0.7341333333333333, 0.7030666666666666, 0.7393333333333333] 0.725511111111111 0.01601197083049252\n"
     ]
    }
   ],
   "source": [
    "!python cma.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
