{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b33a9c8",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427dd5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"your-train-feature-file\") # create from Build_features_extraction.ipynb \n",
    "data_dev = pd.read_csv(\"your-dev-feature-file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6069fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train size: {len(data)} dev size: {len(data_dev)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label to entialment and non-entialment\n",
    "def convert_label(gold_label):\n",
    "  if gold_label == 'contradiction' or gold_label == 'neutral':\n",
    "    return 0\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f734ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['gold_label'].apply(convert_label)\n",
    "data.drop('gold_label', inplace=True, axis=1)\n",
    "data.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "\n",
    "data_dev['label'] = data_dev['gold_label'].apply(convert_label)\n",
    "data_dev.drop('gold_label', inplace=True, axis=1)\n",
    "data_dev.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaf733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert some feature to int\n",
    "def convert_feature(feature):\n",
    "    if feature == \"-\":\n",
    "        return 0\n",
    "    else: #hard or easy\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['swapping'] = data['word_swapping'].apply(convert_feature)\n",
    "data['neg'] = data['negation'].apply(convert_feature)\n",
    "data['sub'] = data['subsequence'].apply(convert_feature)\n",
    "data['cons'] = data['constituent'].apply(convert_feature)\n",
    "data['ant'] = data['antonym'].apply(convert_feature)\n",
    "\n",
    "data_dev['swapping'] = data_dev['word_swapping'].apply(convert_feature)\n",
    "data_dev['neg'] = data_dev['negation'].apply(convert_feature)\n",
    "data_dev['sub'] = data_dev['subsequence'].apply(convert_feature)\n",
    "data_dev['cons'] = data_dev['constituent'].apply(convert_feature)\n",
    "data_dev['ant'] = data_dev['antonym'].apply(convert_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e382202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('word_swapping', inplace=True, axis=1)\n",
    "data.drop('negation', inplace=True, axis=1)\n",
    "data.drop('subsequence', inplace=True, axis=1)\n",
    "data.drop('constituent', inplace=True, axis=1)\n",
    "data.drop('antonym', inplace=True, axis=1)\n",
    "\n",
    "data_dev.drop('word_swapping', inplace=True, axis=1)\n",
    "data_dev.drop('negation', inplace=True, axis=1)\n",
    "data_dev.drop('subsequence', inplace=True, axis=1)\n",
    "data_dev.drop('constituent', inplace=True, axis=1)\n",
    "data_dev.drop('antonym', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b18433",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['label'] != ''\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dev = data_dev['label'] != ''\n",
    "mask_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326dd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.value_counts(), mask_dev.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = data[mask]\n",
    "# _columns_to_keep = ['label', 'neg', 'ant', 'sub', 'cons', 'swapping', 'overlapping score', 'hypo_len'] \n",
    "_columns_to_keep = ['label', 'overlapping score'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83acc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_dev = data_dev[mask]\n",
    "# _columns_to_keep_dev = ['label', 'neg', 'ant', 'sub', 'cons', 'swapping', 'overlapping score', 'hypo_len']\n",
    "_columns_to_keep_dev = ['label', 'overlapping score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep_X_train = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66addf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(_columns_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3038578",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = _data[_columns_to_keep]\n",
    "_data_dev = _data_dev[_columns_to_keep_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb775bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_score = _data[columns_to_keep_X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66443c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091674d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_score = _data_dev[_columns_to_keep_dev]\n",
    "X_test_score[\"pairID\"] = data_dev.pairID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d77505",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data.to_csv(\"train_data_edited.csv\")\n",
    "_data_dev.to_csv(\"dev_data_edited.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb2a7c4",
   "metadata": {},
   "source": [
    "# Bias model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fb4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, svm, metrics, tree, decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, OrthogonalMatchingPursuit\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15edb9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_clfs_params(grid_size):\n",
    "    \"\"\"Define defaults for different classifiers.\n",
    "    Define three types of grids:\n",
    "    Test: for testing your code\n",
    "    Small: small grid\n",
    "    Large: Larger grid that has a lot more parameter sweeps\n",
    "    \"\"\"\n",
    "\n",
    "    clfs = {'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "        'LR': LogisticRegression(penalty='l1', C=1e5),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=True, random_state=0),\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3) \n",
    "            }\n",
    "\n",
    "    large_grid = {'RF':{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "        'LR': {'penalty': ['l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10], 'class_weight': ['balanced', None]},\n",
    "        'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "        'ET': { 'n_estimators': [1,10,100,1000,10000], 'criterion' : ['gini', 'entropy'] ,'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "        'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "        'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "        'NB' : {},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "        'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "        'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }\n",
    "    \n",
    "    small_grid = {'RF':{'n_estimators': [10,100], 'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]}, \n",
    "    'LR': {'penalty': ['l2'], 'C': [0.00001,0.001,0.1,1,10], 'class_weight': ['balanced', None]},\n",
    "    'SGD': {'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': {'n_estimators': [10,100], 'criterion' : ['gini', 'entropy'] ,'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'AB': {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [10,100], 'learning_rate' : [0.001,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [5,50]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }\n",
    "\n",
    "    gam_grid = {\n",
    "        'LR': {'penalty': ['l2'], 'C': [0.01], 'class_weight': ['balanced']},\n",
    "        'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "        'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "        'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "        'NB' : {},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "        'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "           }\n",
    "    \n",
    "    test_grid = {'RF':{'n_estimators': [1], 'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]}, \n",
    "    'LR': {'penalty': ['l2'], 'C': [0.01], 'class_weight': ['balanced', None]},\n",
    "    'SGD': {'loss': ['perceptron'], 'penalty': ['l1', 'elasticnet']},\n",
    "    'ET': {'n_estimators': [1], 'criterion' : ['gini'] ,'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'AB': {'algorithm': ['SAMME'], 'n_estimators': [1]},\n",
    "    'GB': {'n_estimators': [1], 'learning_rate' : [0.1],'subsample' : [0.5], 'max_depth': [1]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini'], 'max_depth': [1],'min_samples_split': [10]},\n",
    "    'SVM' :{'C' :[0.01],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [5], 'weights': ['uniform'], 'algorithm': ['auto']}\n",
    "           }\n",
    "    \n",
    "    if (grid_size == 'gam'):\n",
    "        return clfs, gam_grid\n",
    "    elif (grid_size == 'small'):\n",
    "        return clfs, small_grid\n",
    "    elif (grid_size == 'test'):\n",
    "        return clfs, test_grid\n",
    "    else:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = [i for i in _columns_to_keep if i != 'label']\n",
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_data_edited.csv\")\n",
    "df_dev = pd.read_csv(\"dev_data_edited.csv\")\n",
    "\n",
    "# select features to use\n",
    "features  =  feat\n",
    "X_train = df[features]\n",
    "X_test = df_dev[features]\n",
    "\n",
    "# define label\n",
    "y_train = df['label']\n",
    "y_test = df_dev['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a291742",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK = 0\n",
    "\n",
    "def clf_loop(models_to_run, clfs, grid, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Runs the loop using models_to_run, clfs, gridm and the data\n",
    "    \"\"\"\n",
    "    results_df =  pd.DataFrame(columns=('model_type', 'clf', 'parameters', 'auc-roc', 'acc', 'classification report', 'confusion matrix'))\n",
    "\n",
    "    for n in range(1, 2):\n",
    "        # create training and valdation sets\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        for index, clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            print(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            for p in ParameterGrid(parameter_values):\n",
    "                try:\n",
    "                    clf.set_params(**p)\n",
    "                    y_pred_probs = clf.fit(X_train, y_train).predict(X_test) # HERE\n",
    "                    roc_y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "                    confusion = pd.DataFrame(confusion_matrix(y_test, y_pred_probs, labels = [0, 1]), index = [0, 1], columns = [0, 1])\n",
    "\n",
    "\n",
    "                    # you can also store the model, feature importances, and prediction scores\n",
    "                    # we're only storing the metrics for now\n",
    "                    y_pred_probs_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs, y_test), reverse=True))\n",
    "                    results_df.loc[len(results_df)] = [models_to_run[index], clf, p,\n",
    "                                                       roc_auc_score(y_test, roc_y_pred_probs),\n",
    "                                                       sklearn.metrics.accuracy_score(y_test, y_pred_probs),\n",
    "                                                       classification_report(y_test, y_pred_probs, output_dict=True),\n",
    "                                                       confusion.to_dict(orient=\"list\")]\n",
    "\n",
    "                    #print(results_df)\n",
    "                    if NOTEBOOK == 1:\n",
    "                        plot_precision_recall_n(y_test, y_pred_probs, clf)\n",
    "                except IndexError as e:\n",
    "                    print('Error:', e)\n",
    "                    continue\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd88e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # define grid to use: test, small, large\n",
    "    grid_size = 'gam'\n",
    "    clfs, grid = define_clfs_params(grid_size)\n",
    "\n",
    "    # define models to run\n",
    "    models_to_run=['LR']\n",
    "\n",
    "    # call clf_loop and store results in results_df\n",
    "    results_df = clf_loop(models_to_run, clfs, grid, X_train, X_test, y_train, y_test)\n",
    "    print(results_df)\n",
    "    if NOTEBOOK == 1:\n",
    "        results_df\n",
    "\n",
    "    # save to csv\n",
    "    results_df.to_csv('results.csv', index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60871ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(penalty='l2', C=0.01, class_weight='balanced')\n",
    "t = logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661ad1b",
   "metadata": {},
   "source": [
    "### Get prediction and probability of train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4316124",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = t.predict(X_train)\n",
    "predict_prob = t.predict_proba(X_train)[:,1]\n",
    "X_train_score['prediction'] = predictions\n",
    "X_train_score['prob_score'] = predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb61d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3220c",
   "metadata": {},
   "source": [
    "### Get prediction and probability of test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = t.predict(X_test)\n",
    "predict_prob = t.predict_proba(X_test)[:,1]\n",
    "X_test_score['prediction'] = predictions\n",
    "X_test_score['prob_score'] = predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
