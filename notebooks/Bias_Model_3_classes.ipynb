{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e01642",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afda6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cef251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmultinli_1.0_dev_matched_add_tokens.jsonl\\nmultinli_1.0_dev_matcheddev_anti_bias_add_tokens.jsonl\\nmultinli_1.0_dev_matched.jsonl\\nmultinli_1.0_dev_mismatched.jsonl\\nmultinli_1.0_train_add_tokens.jsonl\\nmultinli_1.0_train.jsonl\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path_dir = \"/ist/ist-share/scads/can/fame_fake_data/data\"\n",
    "\n",
    "# \"\"\"\n",
    "# multinli_1.0_dev_matched_add_tokens.jsonl\n",
    "# multinli_1.0_dev_matcheddev_anti_bias_add_tokens.jsonl\n",
    "# multinli_1.0_dev_matched.jsonl`a\n",
    "# multinli_1.0_dev_mismatched.jsonl\n",
    "# multinli_1.0_train_add_tokens.jsonl\n",
    "# multinli_1.0_train.jsonl\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# train_df = pd.read_csv(\"train_nli_features.csv\")\n",
    "# dev_df = pd.read_csv(\"dev_match_nli_features.csv\")\n",
    "# test_df = pd.read_csv(\"dev_mismatch_nli_features.csv\")\n",
    "# hans_df = pd.read_csv(\"hans_features.csv\")\n",
    "# train_df.shape, dev_df.shape, test_df.shape, hans_df.shape\n",
    "\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_nli_features.csv\")\n",
    "dev_df = pd.read_csv(\"dev_match_nli_features.csv\")\n",
    "test_df = pd.read_csv(\"dev_mismatch_nli_features.csv\")\n",
    "train_df.shape, dev_df.shape, test_df.shape\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546d4ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((392702, 5), (10000, 5), (10000, 5), (30000, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train = pd.DataFrame()\n",
    "new_train[\"pairID\"] = train_df[\"pairID\"]\n",
    "new_train[\"label\"] = train_df[\"gold_label\"]\n",
    "new_train[\"sub\"] = train_df[\"subsequence\"]\n",
    "new_train[\"cons\"] = train_df[\"constituent\"]\n",
    "# new_train[\"lexical_overlap\"] = train_df[\"lexical_overlap\"]\n",
    "new_train[\"overlapping score\"] = train_df[\"overlapping score\"]\n",
    "\n",
    "new_dev = pd.DataFrame()\n",
    "new_dev[\"pairID\"] = dev_df[\"pairID\"]\n",
    "new_dev[\"label\"] = dev_df[\"gold_label\"]\n",
    "new_dev[\"sub\"] = dev_df[\"subsequence\"]\n",
    "new_dev[\"cons\"] = dev_df[\"constituent\"]\n",
    "# new_dev[\"lexical_overlap\"] = dev_df[\"lexical_overlap\"]\n",
    "new_dev[\"overlapping score\"] = dev_df[\"overlapping score\"]\n",
    "\n",
    "new_test = pd.DataFrame()\n",
    "new_test[\"pairID\"] = test_df[\"pairID\"]\n",
    "new_test[\"label\"] = test_df[\"gold_label\"]\n",
    "new_test[\"sub\"] = test_df[\"subsequence\"]\n",
    "new_test[\"cons\"] = test_df[\"constituent\"]\n",
    "# new_test[\"lexical_overlap\"] = test_df[\"lexical_overlap\"]\n",
    "new_test[\"overlapping score\"] = test_df[\"overlapping score\"]\n",
    "\n",
    "new_hans = pd.DataFrame()\n",
    "new_hans[\"pairID\"] = hans_df[\"pairID\"]\n",
    "new_hans[\"label\"] = hans_df[\"gold_label\"]\n",
    "new_hans[\"sub\"] = hans_df[\"subsequence\"]\n",
    "new_hans[\"cons\"] = hans_df[\"constituent\"]\n",
    "# new_hans[\"lexical_overlap\"] = hans_df[\"lexical_overlap\"]\n",
    "new_hans[\"overlapping score\"] = hans_df[\"overlapping score\"]\n",
    "\n",
    "new_train.shape, new_dev.shape, new_test.shape, new_hans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cadd8baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>label</th>\n",
       "      <th>sub</th>\n",
       "      <th>cons</th>\n",
       "      <th>overlapping score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31193n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101457e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134793e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37397e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50563n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pairID       label sub cons  overlapping score\n",
       "0   31193n     neutral   -    -           0.444444\n",
       "1  101457e  entailment   -    -           0.666667\n",
       "2  134793e  entailment   -    -           0.250000\n",
       "3   37397e  entailment   -    -           0.400000\n",
       "4   50563n     neutral   -    -           0.625000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0d96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2 class {entailment: 1, contrandiction: 0, neatral: 0}\n",
    "# def relabel(label):\n",
    "#     if label == 'contradiction' or label == 'neutral':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "\n",
    "# 3 class {entailment: 0, contrandiction: 1, neatral: 2}\n",
    "def relabel(label):\n",
    "    if label == 'contradiction':\n",
    "        return 1\n",
    "    elif label == 'neutral':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# {-: 0, easy: 1, hard: 1}\n",
    "def refeatures(feature):\n",
    "    if feature == 'easy' and feature == 'hard':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec33e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>label</th>\n",
       "      <th>sub</th>\n",
       "      <th>cons</th>\n",
       "      <th>overlapping score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31193n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101457e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134793e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37397e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50563n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pairID  label  sub  cons  overlapping score\n",
       "0   31193n      2    0     0           0.444444\n",
       "1  101457e      0    0     0           0.666667\n",
       "2  134793e      0    0     0           0.250000\n",
       "3   37397e      0    0     0           0.400000\n",
       "4   50563n      2    0     0           0.625000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train[\"label\"] = new_train[\"label\"].apply(relabel)\n",
    "# new_train[\"lexical_overlap\"] = new_train[\"lexical_overlap\"].apply(refeatures)\n",
    "new_train[\"sub\"] = new_train[\"sub\"].apply(refeatures)\n",
    "new_train[\"cons\"] = new_train[\"cons\"].apply(refeatures)\n",
    "\n",
    "new_dev[\"label\"] = new_dev[\"label\"].apply(relabel)\n",
    "# new_dev[\"lexical_overlap\"] = new_dev[\"lexical_overlap\"].apply(refeatures)\n",
    "new_dev[\"sub\"] = new_dev[\"sub\"].apply(refeatures)\n",
    "new_dev[\"cons\"] = new_dev[\"cons\"].apply(refeatures)\n",
    "\n",
    "new_test[\"label\"] = new_test[\"label\"].apply(relabel)\n",
    "# new_test[\"lexical_overlap\"] = new_test[\"lexical_overlap\"].apply(refeatures)\n",
    "new_test[\"sub\"] = new_test[\"sub\"].apply(refeatures)\n",
    "new_test[\"cons\"] = new_test[\"cons\"].apply(refeatures)\n",
    "\n",
    "# new_hans[\"label\"] = new_hans[\"label\"].apply(relabel)\n",
    "# new_hans[\"lexical_overlap\"] = new_hans[\"lexical_overlap\"].apply(refeatures)\n",
    "# new_hans[\"sub\"] = new_hans[\"sub\"].apply(refeatures)\n",
    "# new_hans[\"cons\"] = new_hans[\"cons\"].apply(refeatures)\n",
    "\n",
    "new_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea4fa8",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f068ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, svm, metrics, tree, decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, OrthogonalMatchingPursuit\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "974ef5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_clfs_params(grid_size):\n",
    "    \"\"\"Define defaults for different classifiers.\n",
    "    Define three types of grids:\n",
    "    Test: for testing your code\n",
    "    Small: small grid\n",
    "    Large: Larger grid that has a lot more parameter sweeps\n",
    "    \"\"\"\n",
    "\n",
    "    clfs = {'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "        'LR': LogisticRegression(penalty='l1', C=1e5),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=True, random_state=0),\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3) \n",
    "            }\n",
    "\n",
    "    large_grid = {'RF':{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "        'LR': {'penalty': ['l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10], 'class_weight': ['balanced', None]},\n",
    "        'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "        'ET': { 'n_estimators': [1,10,100,1000,10000], 'criterion' : ['gini', 'entropy'] ,'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "        'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "        'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "        'NB' : {},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "        'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "        'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }\n",
    "    \n",
    "    small_grid = {'RF':{'n_estimators': [10,100], 'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]}, \n",
    "    'LR': {'penalty': ['l2'], 'C': [0.00001,0.001,0.1,1,10], 'class_weight': ['balanced', None]},\n",
    "    'SGD': {'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': {'n_estimators': [10,100], 'criterion' : ['gini', 'entropy'] ,'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'AB': {'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [10,100], 'learning_rate' : [0.001,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [5,50]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }\n",
    "\n",
    "    gam_grid = {\n",
    "        'LR': {'penalty': ['l2'], 'C': [0.01], 'class_weight': ['balanced']},\n",
    "        'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "        'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "        'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "        'NB' : {},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "        'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "           }\n",
    "    \n",
    "    test_grid = {'RF':{'n_estimators': [1], 'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]}, \n",
    "    'LR': {'penalty': ['l2'], 'C': [0.01], 'class_weight': ['balanced', None]},\n",
    "    'SGD': {'loss': ['perceptron'], 'penalty': ['l1', 'elasticnet']},\n",
    "    'ET': {'n_estimators': [1], 'criterion' : ['gini'] ,'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'AB': {'algorithm': ['SAMME'], 'n_estimators': [1]},\n",
    "    'GB': {'n_estimators': [1], 'learning_rate' : [0.1],'subsample' : [0.5], 'max_depth': [1]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini'], 'max_depth': [1],'min_samples_split': [10]},\n",
    "    'SVM' :{'C' :[0.01],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [5], 'weights': ['uniform'], 'algorithm': ['auto']}\n",
    "           }\n",
    "    \n",
    "    if (grid_size == 'gam'):\n",
    "        return clfs, gam_grid\n",
    "    elif (grid_size == 'small'):\n",
    "        return clfs, small_grid\n",
    "    elif (grid_size == 'test'):\n",
    "        return clfs, test_grid\n",
    "    else:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba762f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features to use\n",
    "X_train = new_train.iloc[:, 2:].values\n",
    "X_dev = new_dev.iloc[:, 2:].values\n",
    "X_test = new_test.iloc[:, 2:].values\n",
    "X_hans = new_hans.iloc[:, 2:].values\n",
    "\n",
    "# define label\n",
    "y_train = new_train.iloc[:, 1].values\n",
    "y_dev = new_dev.iloc[:, 1].values\n",
    "y_test = new_test.iloc[:, 1].values\n",
    "y_hans = new_hans.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76755246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK = 0\n",
    "\n",
    "# def clf_loop(models_to_run, clfs, grid, X_train, X_test, y_train, y_test):\n",
    "#     \"\"\"Runs the loop using models_to_run, clfs, gridm and the data\n",
    "#     \"\"\"\n",
    "#     results_df =  pd.DataFrame(columns=('model_type', 'clf', 'parameters', 'auc-roc', 'acc', 'classification report', 'confusion matrix'))\n",
    "\n",
    "#     for n in range(1, 2):\n",
    "#         # create training and valdation sets\n",
    "#         # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "#         for index, clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "#             print(models_to_run[index])\n",
    "#             parameter_values = grid[models_to_run[index]]\n",
    "#             for p in ParameterGrid(parameter_values):\n",
    "#                 try:\n",
    "#                     clf.set_params(**p)\n",
    "#                     y_pred_probs = clf.fit(X_train, y_train).predict(X_test) # HERE\n",
    "#                     roc_y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "#                     confusion = pd.DataFrame(confusion_matrix(y_test, y_pred_probs, labels = [0, 1]), index = [0, 1], columns = [0, 1])\n",
    "\n",
    "\n",
    "#                     # you can also store the model, feature importances, and prediction scores\n",
    "#                     # we're only storing the metrics for now\n",
    "#                     y_pred_probs_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs, y_test), reverse=True))\n",
    "#                     results_df.loc[len(results_df)] = [models_to_run[index], clf, p,\n",
    "#                                                        roc_auc_score(y_test, roc_y_pred_probs),\n",
    "#                                                        sklearn.metrics.accuracy_score(y_test, y_pred_probs),\n",
    "#                                                        classification_report(y_test, y_pred_probs, output_dict=True),\n",
    "#                                                        confusion.to_dict(orient=\"list\")]\n",
    "\n",
    "#                     #print(results_df)\n",
    "#                     if NOTEBOOK == 1:\n",
    "#                         plot_precision_recall_n(y_test, y_pred_probs, clf)\n",
    "#                 except IndexError as e:\n",
    "#                     print('Error:', e)\n",
    "#                     continue\n",
    "\n",
    "#     return results_df\n",
    "\n",
    "NOTEBOOK = 0\n",
    "\n",
    "def clf_loop(models_to_run, clfs, grid, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Runs the loop using models_to_run, clfs, gridm and the data\n",
    "    \"\"\"\n",
    "    results_df =  pd.DataFrame(columns=('model_type', 'clf', 'parameters', 'auc-roc', 'acc', 'classification report', 'confusion matrix'))\n",
    "\n",
    "    for n in range(1, 2):\n",
    "        # create training and valdation sets\n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "        for index, clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            print(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            for p in ParameterGrid(parameter_values):\n",
    "                try:\n",
    "                    clf.set_params(**p)\n",
    "                    y_pred_probs = clf.fit(X_train, y_train).predict(X_test) # HERE\n",
    "                    roc_y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "                    confusion = pd.DataFrame(confusion_matrix(y_test, y_pred_probs, labels = [0, 1, 2]), index = [0, 1, 2], columns = [0, 1, 2])\n",
    "\n",
    "\n",
    "                    # you can also store the model, feature importances, and prediction scores\n",
    "                    # we're only storing the metrics for now\n",
    "                    y_pred_probs_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs, y_test), reverse=True))\n",
    "                    results_df.loc[len(results_df)] = [models_to_run[index], clf, p,\n",
    "                                                       roc_auc_score(y_test, roc_y_pred_probs, multi_class=\"ovr\"),\n",
    "                                                       sklearn.metrics.accuracy_score(y_test, y_pred_probs),\n",
    "                                                       classification_report(y_test, y_pred_probs, output_dict=True),\n",
    "                                                       confusion.to_dict(orient=\"list\")]\n",
    "\n",
    "                    #print(results_df)\n",
    "                    if NOTEBOOK == 1:\n",
    "                        plot_precision_recall_n(y_test, y_pred_probs, clf)\n",
    "                except IndexError as e:\n",
    "                    print('Error:', e)\n",
    "                    continue\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a825ee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "Error: axis 1 is out of bounds for array of dimension 1\n",
      "Empty DataFrame\n",
      "Columns: [model_type, clf, parameters, auc-roc, acc, classification report, confusion matrix]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # define grid to use: test, small, large\n",
    "    grid_size = 'gam'\n",
    "    clfs, grid = define_clfs_params(grid_size)\n",
    "\n",
    "    # define models to run\n",
    "    models_to_run=['LR']\n",
    "\n",
    "    # call clf_loop and store results in results_df\n",
    "    results_df = clf_loop(models_to_run, clfs, grid, X_train, X_dev, y_train, y_dev)\n",
    "    print(results_df)\n",
    "    if NOTEBOOK == 1:\n",
    "        results_df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac036047",
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(penalty='l2', C=0.01, class_weight='balanced')\n",
    "t = logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efdb2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# modelname = 'mnli_lr_model.sav'\n",
    "# pickle.dump(t, open(modelname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5736026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counterfactual=np.array([[0,0,1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2489e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelname = 'mnli_lr_model.sav'\n",
    "# loaded_model = pickle.load(open(modelname, 'rb'))\n",
    "# loaded_model.predict_proba(counterfactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c428f828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loaded_model.predict_proba(counterfactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60632c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8822ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ee4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.predict_proba(counterfactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c3c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = t.predict_proba(X_train).tolist()\n",
    "pred_dev = t.predict_proba(X_dev).tolist()\n",
    "pred_test = t.predict_proba(X_test).tolist()\n",
    "pred_hans = t.predict_proba(X_hans).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "474a8d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((392702, 4), (10000, 4), (10000, 4), (30000, 4))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df = pd.DataFrame()\n",
    "new_train_df[\"gold_label\"] = train_df[\"gold_label\"]\n",
    "new_train_df[\"sentence1\"] = train_df[\"sentence1\"]\n",
    "new_train_df[\"sentence2\"] = train_df[\"sentence2\"]\n",
    "new_train_df[\"bias_probs\"] = pred_train\n",
    "\n",
    "new_dev_df = pd.DataFrame()\n",
    "new_dev_df[\"gold_label\"] = dev_df[\"gold_label\"]\n",
    "new_dev_df[\"sentence1\"] = dev_df[\"sentence1\"]\n",
    "new_dev_df[\"sentence2\"] = dev_df[\"sentence2\"]\n",
    "new_dev_df[\"bias_probs\"] = pred_dev\n",
    "\n",
    "new_test_df = pd.DataFrame()\n",
    "new_test_df[\"gold_label\"] = test_df[\"gold_label\"]\n",
    "new_test_df[\"sentence1\"] = test_df[\"sentence1\"]\n",
    "new_test_df[\"sentence2\"] = test_df[\"sentence2\"]\n",
    "new_test_df[\"bias_probs\"] = pred_test\n",
    "\n",
    "new_hans_df = pd.DataFrame()\n",
    "new_hans_df[\"gold_label\"] = hans_df[\"gold_label\"]\n",
    "new_hans_df[\"sentence1\"] = hans_df[\"premise\"]\n",
    "new_hans_df[\"sentence2\"] = hans_df[\"hypothesis\"]\n",
    "new_hans_df[\"bias_probs\"] = pred_hans\n",
    "\n",
    "new_train_df.shape, new_dev_df.shape, new_test_df.shape, new_hans_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2870a3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df.isnull().sentence1.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d7ed594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nall to n\\/a\n",
    "new_train_df.sentence2 = new_train_df.sentence2.fillna('n\\/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1f9aff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>bias_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Conceptually cream skimming has two basic dime...</td>\n",
       "      <td>Product and geography are what make cream skim...</td>\n",
       "      <td>[0.33998758770118354, 0.34308485129272914, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>you know during the season and i guess at at y...</td>\n",
       "      <td>You lose the things to the following level if ...</td>\n",
       "      <td>[0.5033300255414216, 0.2859676470184237, 0.210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>One of our number will carry out your instruct...</td>\n",
       "      <td>A member of my team will execute your orders w...</td>\n",
       "      <td>[0.21996300239532512, 0.36692578681271204, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "      <td>How do you know? All this is their information...</td>\n",
       "      <td>This information belongs to them.</td>\n",
       "      <td>[0.30998086898840815, 0.35088778924181063, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>yeah i tell you what though if you go price so...</td>\n",
       "      <td>The tennis shoes have a range of prices.</td>\n",
       "      <td>[0.4718813548036844, 0.29858867684924567, 0.22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gold_label                                          sentence1  \\\n",
       "0     neutral  Conceptually cream skimming has two basic dime...   \n",
       "1  entailment  you know during the season and i guess at at y...   \n",
       "2  entailment  One of our number will carry out your instruct...   \n",
       "3  entailment  How do you know? All this is their information...   \n",
       "4     neutral  yeah i tell you what though if you go price so...   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  Product and geography are what make cream skim...   \n",
       "1  You lose the things to the following level if ...   \n",
       "2  A member of my team will execute your orders w...   \n",
       "3                  This information belongs to them.   \n",
       "4           The tennis shoes have a range of prices.   \n",
       "\n",
       "                                          bias_probs  \n",
       "0  [0.33998758770118354, 0.34308485129272914, 0.3...  \n",
       "1  [0.5033300255414216, 0.2859676470184237, 0.210...  \n",
       "2  [0.21996300239532512, 0.36692578681271204, 0.4...  \n",
       "3  [0.30998086898840815, 0.35088778924181063, 0.3...  \n",
       "4  [0.4718813548036844, 0.29858867684924567, 0.22...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aabf6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_json = new_train_df.to_json(orient='records', lines=True)\n",
    "with open('train_prob_korn_lr_overlapping_sample_weight_3class.jsonl', 'w') as json_file:\n",
    "    json_file.write(train_json)\n",
    "\n",
    "dev_json = new_dev_df.to_json(orient='records', lines=True)    \n",
    "with open('dev_prob_korn_lr_overlapping_sample_weight_3class.jsonl', 'w') as json_file:\n",
    "    json_file.write(dev_json)\n",
    "\n",
    "test_json = new_test_df.to_json(orient='records', lines=True)     \n",
    "with open('test_prob_korn_lr_overlapping_sample_weight_3class.jsonl', 'w') as json_file:\n",
    "    json_file.write(test_json)\n",
    "    \n",
    "hans_json = new_hans_df.to_json(orient='records', lines=True)     \n",
    "with open('hans_prob_korn_lr_overlapping_sample_weight_3class.jsonl', 'w') as json_file:\n",
    "    json_file.write(hans_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d5b7e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>label</th>\n",
       "      <th>sub</th>\n",
       "      <th>cons</th>\n",
       "      <th>lexical_overlap</th>\n",
       "      <th>overlapping score</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob_score</th>\n",
       "      <th>weight_score</th>\n",
       "      <th>trimmed_weight_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31193n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343085</td>\n",
       "      <td>0.431538</td>\n",
       "      <td>0.431538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101457e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285968</td>\n",
       "      <td>0.509842</td>\n",
       "      <td>0.509842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134793e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.366926</td>\n",
       "      <td>0.400783</td>\n",
       "      <td>0.400783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37397e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350888</td>\n",
       "      <td>0.421347</td>\n",
       "      <td>0.421347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50563n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298589</td>\n",
       "      <td>0.491978</td>\n",
       "      <td>0.491978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pairID  label  sub  cons  lexical_overlap  overlapping score  prediction  \\\n",
       "0   31193n      2    0     0                0           0.444444           1   \n",
       "1  101457e      0    0     0                0           0.666667           0   \n",
       "2  134793e      0    0     0                0           0.250000           2   \n",
       "3   37397e      0    0     0                0           0.400000           1   \n",
       "4   50563n      2    0     0                0           0.625000           0   \n",
       "\n",
       "   prob_score  weight_score  trimmed_weight_score  \n",
       "0    0.343085      0.431538              0.431538  \n",
       "1    0.285968      0.509842              0.509842  \n",
       "2    0.366926      0.400783              0.400783  \n",
       "3    0.350888      0.421347              0.421347  \n",
       "4    0.298589      0.491978              0.491978  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = t.predict(X_train)\n",
    "predict_prob = t.predict_proba(X_train)[:,1]\n",
    "new_train['prediction'] = predictions\n",
    "new_train['prob_score'] = predict_prob\n",
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f06c4956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': 130900, '1': 130903, '0': 130899}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # just for checking 2 class\n",
    "# score = {'1': 0, '0': 0}\n",
    "# for i in range(len(new_train['label'])):\n",
    "#     if new_train['label'][i] == 1:\n",
    "#         score['1'] += 1\n",
    "#     else:\n",
    "#         score['0'] += 1\n",
    "\n",
    "# just for checking 3 class\n",
    "score = {'2': 0, '1': 0, '0': 0}\n",
    "for i in range(len(new_train['label'])):\n",
    "    if new_train['label'][i] == 2:\n",
    "        score['2'] += 1\n",
    "    elif new_train['label'][i] == 1:\n",
    "        score['1'] += 1\n",
    "    else:\n",
    "        score['0'] += 1\n",
    "        \n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d237055e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79717, 16611, 34571],\n",
       "       [49593, 19884, 61426],\n",
       "       [37563, 19929, 73408]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = confusion_matrix(new_train['label'], new_train['prediction'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d28bec4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219693"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(new_train['label'])):\n",
    "    if new_train['label'][i] != new_train['prediction'][i]:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7b7ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for i in range(len(new_train['prob_score'])):\n",
    "    all_scores.append(new_train['prob_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3506127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3691658644713939, 0.17571198816068542)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(all_scores), min(all_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "451287ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps\n",
    "def give_weight(label, prob_score):\n",
    "    result = 1 / prob_score\n",
    "    return result\n",
    "\n",
    "# # clark\n",
    "# def give_weight(label, prob_score):\n",
    "#     result = 1 - prob_score\n",
    "#     return result\n",
    "\n",
    "# # focal\n",
    "# def give_weight(label, prob_score):\n",
    "#     result = (1 - prob_score)**2\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9fa15edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>label</th>\n",
       "      <th>sub</th>\n",
       "      <th>cons</th>\n",
       "      <th>lexical_overlap</th>\n",
       "      <th>overlapping score</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob_score</th>\n",
       "      <th>weight_score</th>\n",
       "      <th>trimmed_weight_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31193n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343085</td>\n",
       "      <td>2.914731</td>\n",
       "      <td>0.656915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101457e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285968</td>\n",
       "      <td>3.496899</td>\n",
       "      <td>0.714032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134793e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.366926</td>\n",
       "      <td>2.725347</td>\n",
       "      <td>0.633074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37397e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350888</td>\n",
       "      <td>2.849914</td>\n",
       "      <td>0.649112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50563n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298589</td>\n",
       "      <td>3.349089</td>\n",
       "      <td>0.701411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pairID  label  sub  cons  lexical_overlap  overlapping score  prediction  \\\n",
       "0   31193n      2    0     0                0           0.444444           1   \n",
       "1  101457e      0    0     0                0           0.666667           0   \n",
       "2  134793e      0    0     0                0           0.250000           2   \n",
       "3   37397e      0    0     0                0           0.400000           1   \n",
       "4   50563n      2    0     0                0           0.625000           0   \n",
       "\n",
       "   prob_score  weight_score  trimmed_weight_score  \n",
       "0    0.343085      2.914731              0.656915  \n",
       "1    0.285968      3.496899              0.714032  \n",
       "2    0.366926      2.725347              0.633074  \n",
       "3    0.350888      2.849914              0.649112  \n",
       "4    0.298589      3.349089              0.701411  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train['weight_score'] = new_train[['label', 'prob_score']].apply(lambda x: give_weight(*x), axis=1)\n",
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9eb39481",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weight = []\n",
    "for i in range(len(new_train['weight_score'])):\n",
    "    train_weight.append(new_train['weight_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6dcb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.69113132500395, 2.708809497952616)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_weight), min(train_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a381023d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                   2.000000\n",
       "sub                     0.000000\n",
       "cons                    0.000000\n",
       "lexical_overlap         0.000000\n",
       "overlapping score       0.800000\n",
       "prediction              2.000000\n",
       "prob_score              0.369002\n",
       "weight_score            4.127717\n",
       "trimmed_weight_score    0.757735\n",
       "Name: 0.95, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1fad0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_score = new_train.quantile(q=0.95).weight_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86f54afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(weight_score):\n",
    "    if weight_score >= w_score:\n",
    "        return w_score\n",
    "    else: \n",
    "        return weight_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "549eb8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>label</th>\n",
       "      <th>sub</th>\n",
       "      <th>cons</th>\n",
       "      <th>lexical_overlap</th>\n",
       "      <th>overlapping score</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob_score</th>\n",
       "      <th>weight_score</th>\n",
       "      <th>trimmed_weight_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31193n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343085</td>\n",
       "      <td>2.914731</td>\n",
       "      <td>2.914731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101457e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285968</td>\n",
       "      <td>3.496899</td>\n",
       "      <td>3.496899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134793e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.366926</td>\n",
       "      <td>2.725347</td>\n",
       "      <td>2.725347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37397e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350888</td>\n",
       "      <td>2.849914</td>\n",
       "      <td>2.849914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50563n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298589</td>\n",
       "      <td>3.349089</td>\n",
       "      <td>3.349089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pairID  label  sub  cons  lexical_overlap  overlapping score  prediction  \\\n",
       "0   31193n      2    0     0                0           0.444444           1   \n",
       "1  101457e      0    0     0                0           0.666667           0   \n",
       "2  134793e      0    0     0                0           0.250000           2   \n",
       "3   37397e      0    0     0                0           0.400000           1   \n",
       "4   50563n      2    0     0                0           0.625000           0   \n",
       "\n",
       "   prob_score  weight_score  trimmed_weight_score  \n",
       "0    0.343085      2.914731              2.914731  \n",
       "1    0.285968      3.496899              3.496899  \n",
       "2    0.366926      2.725347              2.725347  \n",
       "3    0.350888      2.849914              2.849914  \n",
       "4    0.298589      3.349089              3.349089  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train['trimmed_weight_score'] = new_train['weight_score'].apply(trim)\n",
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0904db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv(\"train_overlapping_feature_weight_ps3class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11844fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
