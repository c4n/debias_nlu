{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "# import torch\n",
    "\n",
    "from cma import report_CMA\n",
    "import fuse, causal_utils\n",
    "from kl_general import DEFAULT_CONFIG as ESTIMATE_C_DEFAULT_CONFIG\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from my_package.models.traditional.classifier import Classifier\n",
    "from my_package.utils.handcrafted_features.counter import count_negations\n",
    "from my_package.utils.handcrafted_features.overlap import get_lexical_overlap, get_entities_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"qqp\" # fever or qqp\n",
    "IS_CORRECTION = False\n",
    "\n",
    "IS_GENERATE_NEW_BIAS_PRED = False\n",
    "\n",
    "_MODEL_PATH = {\n",
    "    # outputs_fever_bert_base_1 outputs_fever_weighted_bert_1 outputs_fever_poe_bert_1\n",
    "    \"fever\": \"../results/outputs_fever_bert_base_1\", \n",
    "    # outputs_qqp_bert_base_1 outputs_qqp_weighted_bert_1 outputs_qqp_poe_bert_1\n",
    "    \"qqp\": \"/raid/can/nli_models/qqp_bias/self_distill/qqp_bert_base_self_distill_bias\" # \"../results/outputs_qqp_bert_base_1\"\n",
    "}\n",
    "RESULT_PATH = \"/raid/can/nli_models/qqp_bias/self_distill/\" # \"../results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BIAS_CLASS = {\n",
    "    \"fever\": \"REFUTES\",\n",
    "    \"qqp\": \"1\"\n",
    "}\n",
    "_POSSIBLE_LABELS = {\n",
    "    \"fever\": (\"SUPPORTS\", \"NOT ENOUGH INFO\", \"REFUTES\"),\n",
    "    \"qqp\": (\"0\", \"1\")\n",
    "}\n",
    "\n",
    "\n",
    "_DATA_PATH = {\n",
    "    \"fever\": \"../data/fact_verification\",\n",
    "    \"qqp\": \"/ist/users/patompornp/debias_nlu/data/paraphrase_identification\" # \"../data/paraphrase_identification\"\n",
    "}\n",
    "\n",
    "\n",
    "_SENT1_KEYS = {\n",
    "    \"fever\": (\"claim\", \"claim\", \"claim\"),\n",
    "    \"qqp\": (\"sentence1\", \"sentence1\")\n",
    "}\n",
    "_SENT2_KEYS = {\n",
    "    \"fever\": (\"evidence\", \"evidence_sentence\", \"evidence\"),\n",
    "    \"qqp\": (\"sentence2\", \"sentence2\")\n",
    "}\n",
    "_LABEL_KEYS = {\n",
    "    \"fever\": (\"gold_label\", \"label\", \"label\"),\n",
    "    \"qqp\": (\"is_duplicate\", \"is_duplicate\")\n",
    "}\n",
    "_TEST_FILES = {\n",
    "    \"fever\": (\n",
    "        \"fever.dev.jsonl\",\n",
    "        \"fever_symmetric_v0.1.test.jsonl\",\n",
    "        \"fever_symmetric_v0.2.test.jsonl\",\n",
    "    ),\n",
    "    \"qqp\": (\n",
    "        \"qqp.dev.jsonl\",\n",
    "        \"paws.dev_and_test.jsonl\"\n",
    "    )\n",
    "}\n",
    "_TEST_SETS = {\n",
    "    \"fever\": (\n",
    "        \"fever_dev\",\n",
    "        \"fever_sym1\",\n",
    "        \"fever_sym2\",\n",
    "    ),\n",
    "    \"qqp\": (\n",
    "        \"qqp_dev\",\n",
    "        \"qqp_paws\"\n",
    "    )\n",
    "}\n",
    "\n",
    "_BIAS_MODEL_PATH = {\n",
    "    \"fever\": \"../results/fever/bias_model\",\n",
    "    \"qqp\": \"../results/qqp/bias_model\"\n",
    "}\n",
    "\n",
    "_BIAS_VAL_PRED_FILE = {\n",
    "    \"fever\": \"weighted_fever.val.jsonl\",\n",
    "    \"qqp\": \"qqp_val_overlap_only_bias_weighted.jsonl\" # \"weighted_qqp.val.jsonl\",\n",
    "}\n",
    "_MODEL_VAL_PRED_FILE = {\n",
    "    \"fever\": \"raw_fever.val.jsonl\",\n",
    "    \"qqp\": \"raw_qqp.val.jsonl\",\n",
    "}\n",
    "\n",
    "MODEL_PROB_KEY = \"probs\"\n",
    "BIAS_PROB_KEY = \"bias_prob\"\n",
    "\n",
    "# Fusion method\n",
    "FUSION = fuse.sum_fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS_CLASS = _BIAS_CLASS[DATASET]\n",
    "POSSIBLE_LABELS = _POSSIBLE_LABELS[DATASET]\n",
    "ESTIMATE_C_DEFAULT_CONFIG[\"N_LABELS\"] = len(POSSIBLE_LABELS)\n",
    "\n",
    "ROOT_DATA_PATH = \"../data\"\n",
    "DATA_PATH = _DATA_PATH[DATASET]\n",
    "TEST_FILES = _TEST_FILES[DATASET]\n",
    "TEST_SETS = _TEST_SETS[DATASET]\n",
    "SENT1_KEYS = _SENT1_KEYS[DATASET]\n",
    "SENT2_KEYS = _SENT2_KEYS[DATASET]\n",
    "LABEL_KEYS = _LABEL_KEYS[DATASET]\n",
    "WEIGHT_KEY = \"sample_weight\"\n",
    "\n",
    "BIAS_MODEL_PATH = _BIAS_MODEL_PATH[DATASET] \n",
    "MODEL_PATH = _MODEL_PATH[DATASET]\n",
    "\n",
    "\n",
    "BIAS_VAL_PRED_FILE = _BIAS_VAL_PRED_FILE[DATASET]\n",
    "MODEL_VAL_PRED_FILE = _MODEL_VAL_PRED_FILE[DATASET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fever_classifier():\n",
    "    POSSIBLE_LABELS = _POSSIBLE_LABELS[\"fever\"]\n",
    "    feature_extractors = [\n",
    "        lambda s1, s2: count_negations(s1),\n",
    "        lambda s1, s2: count_negations(s2),\n",
    "        get_lexical_overlap,\n",
    "        get_entities_overlap\n",
    "    ]\n",
    "    classifier = Classifier(\n",
    "        possible_labels=POSSIBLE_LABELS,\n",
    "        feature_extractors=feature_extractors\n",
    "    )\n",
    "    classifier.load(BIAS_MODEL_PATH)\n",
    "    return classifier\n",
    "\n",
    "def get_qqp_classifier():\n",
    "    POSSIBLE_LABELS = _POSSIBLE_LABELS[\"qqp\"]\n",
    "    feature_extractors = [\n",
    "        get_lexical_overlap,\n",
    "        get_entities_overlap\n",
    "    ]\n",
    "    classifier = Classifier(\n",
    "        possible_labels=POSSIBLE_LABELS,\n",
    "        feature_extractors=feature_extractors\n",
    "    )\n",
    "    classifier.load(BIAS_MODEL_PATH)\n",
    "    return classifier\n",
    "\n",
    "MAP_GET_CLS = {\n",
    "    \"fever\": get_fever_classifier,\n",
    "    \"qqp\": get_qqp_classifier\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DATASET == \"fever\":\n",
    "#     classifier = get_fever_classifier()\n",
    "# elif DATASET == \"qqp\":\n",
    "#     classifier = get_qqp_classifier()\n",
    "# else:\n",
    "#     raise NotImplementedError(\"No classifier for %s does\"%DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute average input for bias model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_jsonl(file_path: str) -> List[Dict[str, Union[str, int]]]:\n",
    "    output = []\n",
    "    f = open(file_path, 'r')\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        doc = json.loads(line)\n",
    "        output.append(doc)\n",
    "        line = f.readline()\n",
    "    f.close()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Pate is a type of fish .',\n",
       "  'Pate , paÌ‚te , or paste , a term for the interior body -LRB- non-rind portion -RRB- of cheese , described by its texture , density , and color'),\n",
       " ('Floyd Mayweather Jr. was born in New York in February 24 , 1977 .',\n",
       "  'Tabure Thabo Bogopa Junior -LRB- born March 12 , 1987 -RRB- , who performs under the stage name JR , is a South African rapper .')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = _read_jsonl(os.path.join(DATA_PATH, \"%s.val.jsonl\"%DATASET))\n",
    "val_data = [\n",
    "    (x[SENT1_KEYS[0]], x[SENT2_KEYS[0]])\n",
    "    for x in val_data\n",
    "]\n",
    "print(len(val_data))\n",
    "val_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape feature vecs:  (5000, 604)\n",
      "input_a0 len:  604\n",
      "[0.0, 0.0, 0.007533333333333333, 0.0, 0.0068, 0.0, 0.004, 0.008666666666666673, 0.0, 0.0022, 0.0, 0.0, 0.00295, 0.0, 0.0, 0.008066666666666668, 0.0, 0.0, 0.0, 0.0011333333333333332, 0.0038, 0.005066666666666663, 0.0011, 0.0063, 0.0, 0.0, 0.011733333333333354, 0.0, 0.002, 0.0043, 0.003759999999999995, 0.0, 0.0068, 0.0032000000000000023, 0.0, 0.0030000000000000014, 0.007159999999999995, 0.0, 0.006133333333333328, 0.0026, 0.010800000000000018, 0.0, 0.0051, 0.00775, 0.0, 0.0, 0.0036, 0.0022000000000000006, 0.0024666666666666674, 0.0009, 0.00691999999999999, 0.00965, 0.0, 0.0048, 0.002666666666666668, 0.0044, 0.0014, 0.0019, 0.002, 0.0024, 0.0025333333333333345, 0.0046, 0.0032, 0.0027, 0.0082, 0.0024000000000000002, 0.00845, 0.0, 0.005133333333333328, 0.0033333333333333357, 0.0, 0.0012, 0.0008, 0.0018, 0.0005, 0.0, 0.0009, 0.00435, 0.0, 0.0, 0.0009, 0.0012, 0.0014800000000000008, 0.0005, 0.01599999999999999, 0.0011333333333333334, 0.0007, 0.0017, 0.00445, 0.0, 0.0004666666666666666, 0.0012, 0.0002, 0.0092, 0.0006, 0.0077, 0.0005, 0.0014, 0.0030000000000000005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012266666666666674, 0.0, 0.0113, 0.0, 0.0, 0.02120000000000011, 0.0, 0.0, 0.0, 0.0032, 0.0028000000000000004, 0.0, 0.0026000000000000007, 0.0006666666666666666, 0.003933333333333333, 0.0, 0.010533333333333355, 0.00445, 0.0, 0.0016, 0.0114, 0.0, 0.00920000000000001, 0.0019, 0.004466666666666664, 0.0, 0.0, 0.0024999999999999988, 0.0, 0.0, 0.00575, 0.00225, 0.0025333333333333345, 0.002, 0.0016, 0.0037, 0.0057, 0.015466666666666656, 0.00035, 0.0113, 0.0, 0.0, 0.0, 0.0098, 0.0, 0.0105, 0.018133333333333293, 0.0027, 0.0052, 0.00275, 0.0018, 0.0038, 0.002, 0.0038, 0.0029, 0.002, 0.0054, 0.0015, 0.0, 0.0, 0.0, 0.0024, 0.0006, 0.0012, 0.002, 0.0029, 0.0036, 0.0, 0.004, 0.0, 0.0, 0.0014, 0.0, 0.0, 0.0, 0.0037, 0.001, 0.0029, 0.0024000000000000002, 0.0021, 0.0, 0.0014, 0.0015, 0.0017, 0.0, 0.0, 0.0002, 0.0018, 0.0031, 0.0008, 0.0, 0.0, 0.0056, 0.0022, 0.0026, 0.0048, 0.0019, 0.0026, 0.0026, 0.0029, 0.0036, 0.0012, 0.0058, 0.001, 0.0042, 0.003, 0.0013, 0.004, 0.0034, 0.0043, 0.0021, 0.0044, 0.007399999999999999, 0.0012, 0.0005, 0.0078, 0.001, 0.0009, 0.002, 0.0026, 0.0007, 0.0008, 0.0004, 0.0027, 0.001, 0.0032, 0.001, 0.0003, 0.0006, 0.0009, 0.001, 0.0024, 0.0004, 0.002, 0.0002, 0.0016, 0.0017, 0.0009, 0.0004, 0.0006, 0.0033, 0.0, 0.0073, 0.013, 0.003333333333333335, 0.005133333333333329, 0.0, 0.00713333333333333, 0.0, 0.0, 0.006599999999999993, 0.0006, 0.0032, 0.0, 0.0035, 0.009466666666666674, 0.009866666666666678, 0.0, 0.0025, 0.0, 0.0, 0.0012666666666666662, 0.0018, 0.00913333333333334, 0.0022, 0.0, 0.0005, 0.0, 0.0013, 0.0, 0.0008, 0.0054, 0.0005, 0.0007, 0.0005, 0.0001, 0.0014, 0.0024, 0.0012, 0.0026, 0.0006, 0.0012, 0.0006, 0.0, 0.0743760000000015, 0.024876923076923654, 0.01625714285714288, 0.0066, 0.039959999999999274, 0.0075, 0.014800000000000006, 0.016133333333333326, 0.007933333333333336, 0.019566666666666736, 0.04056666666666647, 0.01295, 0.0029333333333333308, 0.009533333333333342, 0.00455, 0.0043, 0.00665, 0.005866666666666661, 0.011266666666666683, 0.0087, 0.0101, 0.014366666666666649, 0.00555, 0.0004600000000000001, 0.00515, 0.009680000000000027, 0.00686666666666666, 0.006133333333333326, 0.0046666666666666645, 0.004, 0.0, 0.11413333333333264, 0.0056000000000000025, 0.007799999999999997, 0.11504000000000437, 0.0058333333333333405, 0.007466666666666668, 0.02955, 0.00695, 0.003314285714285711, 0.02080000000000014, 0.00753333333333333, 0.0, 0.007399999999999997, 0.0093, 0.01195, 0.008133333333333338, 0.0045, 0.008866666666666672, 0.006533333333333326, 0.002, 0.011720000000000038, 0.007266666666666667, 0.0013714285714285716, 0.003319999999999996, 0.0017, 0.00525, 0.0039, 0.010080000000000016, 0.02297142857142852, 0.0020399999999999997, 0.0045, 0.0198, 0.16115, 0.016633333333333354, 0.009966666666666645, 0.0066, 0.041493333333332626, 0.01599999999999998, 0.0033, 0.0084, 0.0089, 0.0048, 0.01100000000000004, 0.004199999999999999, 0.0052, 0.00545, 0.0018, 0.035866666666666464, 0.008825, 0.0076, 0.0028, 0.0033333333333333344, 0.0028, 0.00283333333333333, 0.0041199999999999935, 0.00135, 0.003466666666666667, 0.0044, 0.010777777777777846, 0.0083, 0.008166666666666668, 0.0397555555555563, 0.008133333333333333, 0.0046, 0.01625, 0.006733333333333329, 0.021560000000000183, 0.0029999999999999983, 0.0071, 0.0201, 0.018360000000000116, 0.004266666666666664, 0.002266666666666666, 0.0081, 0.0154, 0.003799999999999999, 0.0109, 0.012666666666666689, 0.0047, 0.0022, 0.004, 0.0028, 0.007333333333333333, 0.0087, 0.005, 0.0017999999999999997, 0.0088, 0.005, 0.0027, 0.0053, 0.0029333333333333355, 0.0055, 0.002, 0.00535, 0.0047, 0.0023333333333333344, 0.0078, 0.0043, 0.0036, 0.0058, 0.0086, 0.005199999999999996, 0.014933333333333344, 0.033400000000000055, 0.022933333333333233, 0.021825, 0.013533333333333349, 0.0129, 0.0148, 0.0043999999999999985, 0.004142857142857152, 0.02325, 0.0, 0.004599999999999997, 0.00453333333333333, 0.0048, 0.022, 0.005199999999999999, 0.0021, 0.0119, 0.01155, 0.0029, 0.0022000000000000006, 0.0024666666666666674, 0.0013, 0.0018, 0.0056, 0.010200000000000027, 0.004999999999999996, 0.0017999999999999997, 0.0069, 0.004266666666666665, 0.011, 0.0006000000000000001, 0.00185, 0.0021, 0.002600000000000001, 0.003, 0.0064, 0.0998666666666652, 0.028239999999999613, 0.002, 0.02719999999999992, 0.003, 0.0032000000000000015, 0.01572000000000008, 0.0073, 0.0008, 0.008933333333333342, 0.0035, 0.008600000000000003, 0.0024, 0.0038666666666666663, 0.0014666666666666662, 0.0044, 0.00733333333333333, 0.0016, 0.0058, 0.00905, 0.0032, 0.00639999999999999, 0.0046666666666666645, 0.0037333333333333337, 0.04626666666666703, 0.0006, 0.0026, 0.0015, 0.0019, 0.01093333333333335, 0.0006, 0.0023, 0.0017, 0.0064, 0.0031, 0.003466666666666667, 0.009866666666666683, 0.0008, 0.004666666666666664, 0.003800000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0188, 0.00795, 0.06793964911550505, 0.03590909090909158]\n"
     ]
    }
   ],
   "source": [
    "# feature_vecs = []\n",
    "# for data in val_data:\n",
    "#     feature_vecs.append(\n",
    "#         classifier.normalizer.transform( # 2) Normalize vector\n",
    "#             [classifier._transform(data),] # 1) Text to raw vector\n",
    "#         )[0]\n",
    "#     )\n",
    "# feature_vecs = np.array(feature_vecs)\n",
    "# print(\"Shape feature vecs: \", feature_vecs.shape)\n",
    "\n",
    "# input_a0 = np.mean(feature_vecs, axis=0).tolist()\n",
    "# print(\"input_a0 len: \", len(input_a0))\n",
    "# print(input_a0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(\n",
    "    _input: List[float]\n",
    ") -> List[float]:\n",
    "    return classifier.model.predict_proba([_input, ]).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40402256167499867, 0.46030682167588166, 0.1356706166491197]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_pred(input_a0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict bias prob in multiple test sets (This should be done only one time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"fever\":\n",
    "    def get_weight(prob_score_ground_truth_class: float) -> float:\n",
    "        return 1/prob_score_ground_truth_class\n",
    "elif DATASET == 'qqp':\n",
    "    def get_weight(prob_score_bias_class: float, ground_truth_label: str, bias_label: str = BIAS_CLASS) -> float:\n",
    "        if ground_truth_label == bias_label:\n",
    "            return 1/prob_score_bias_class\n",
    "        return 1/(1-prob_score_bias_class)\n",
    "else:\n",
    "    raise NotImplementedError(\"No classifier for %s does\"%DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLE = -1\n",
    "\n",
    "\n",
    "if DATASET == \"fever\":\n",
    "    def inference_prob_to_index(x: List[Dict[str, float]]) -> List[float]:\n",
    "        return [\n",
    "            x[\"SUPPORTS\"],\n",
    "            x[\"NOT ENOUGH INFO\"],\n",
    "            x[\"REFUTES\"]\n",
    "        ]\n",
    "elif DATASET == \"qqp\":\n",
    "    def inference_prob_to_index(x: List[Dict[str, float]]) -> List[float]:\n",
    "        return [\n",
    "            x[\"0\"],\n",
    "            x[\"1\"]\n",
    "        ]\n",
    "\n",
    "def write_weight_to_file(\n",
    "    DATA_FILE: str,\n",
    "    OUTPUT_DATA_FILE: str,\n",
    "    _classifier\n",
    ") -> None:\n",
    "    f_output = open(OUTPUT_DATA_FILE, 'w')\n",
    "\n",
    "    N_SAMPLE = 0\n",
    "\n",
    "    with open(DATA_FILE, 'r') as fh:\n",
    "        line = fh.readline()\n",
    "        while line:\n",
    "            datapoint = json.loads(line)\n",
    "            ground_truth_label = datapoint[LABEL_KEY]\n",
    "            x = [[datapoint[SENT1_KEY], datapoint[SENT2_KEY]]]\n",
    "\n",
    "            probs = _classifier.inference(x)[0]\n",
    "            prob = probs[ground_truth_label]\n",
    "            if DATASET == 'fever':\n",
    "                weight = get_weight(prob_score_ground_truth_class=prob)\n",
    "            elif DATASET == 'qqp':\n",
    "                weight = get_weight(\n",
    "                    prob_score_bias_class=prob,\n",
    "                    ground_truth_label=str(ground_truth_label),\n",
    "                    bias_label=BIAS_CLASS\n",
    "                )\n",
    "                \n",
    "            if datapoint.get(\"weight\", None) != None:\n",
    "                del datapoint[\"weight\"] # only for fever\n",
    "                \n",
    "            f_output.write(\"%s\\n\"%json.dumps({\n",
    "                **datapoint,\n",
    "                WEIGHT_KEY: weight,\n",
    "                \"bias_probs\": inference_prob_to_index(probs),\n",
    "                \"bias_prob\": prob\n",
    "            }))\n",
    "\n",
    "            N_SAMPLE += 1\n",
    "            if MAX_SAMPLE != -1 and N_SAMPLE == MAX_SAMPLE:\n",
    "                break\n",
    "            line = fh.readline()\n",
    "\n",
    "    f_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if IS_GENERATE_NEW_BIAS_PRED:\n",
    "#     for SENT1_KEY, SENT2_KEY, LABEL_KEY, test_file in zip(SENT1_KEYS, SENT2_KEYS, LABEL_KEYS, TEST_FILES):\n",
    "#         print(\"test_file: \", test_file)\n",
    "#         _test_file = os.path.join(DATA_PATH, test_file)\n",
    "#         _pred_test_file = os.path.join(DATA_PATH, \"weighted_%s\"%test_file)\n",
    "#         write_weight_to_file(\n",
    "#             DATA_FILE = _test_file,\n",
    "#             OUTPUT_DATA_FILE = _pred_test_file,\n",
    "#             _classifier = classifier\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal Mediation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results/outputs_fever_bert_base_1_seed23370/utama_distil/utama_distill_model_0/',\n",
       " '../results/outputs_fever_bert_base_1_seed33370/utama_distil/utama_distill_model_0/',\n",
       " '../results/outputs_fever_bert_base_1_seed43370/utama_distil/utama_distill_model_0/',\n",
       " '../results/outputs_fever_bert_base_1_seed53370/utama_distil/utama_distill_model_0/',\n",
       " '../results/outputs_fever_bert_base_1_seed63370/utama_distil/utama_distill_model_0/']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed_paths = [\n",
    "#     '../results/outputs_fever_bert_base_1_seed23370/utama_distil/utama_distill_model_0/',\n",
    "#     '../results/outputs_fever_bert_base_1_seed33370/utama_distil/utama_distill_model_0/',\n",
    "#     '../results/outputs_fever_bert_base_1_seed43370/utama_distil/utama_distill_model_0/',\n",
    "#     '../results/outputs_fever_bert_base_1_seed53370/utama_distil/utama_distill_model_0/',\n",
    "#     '../results/outputs_fever_bert_base_1_seed63370/utama_distil/utama_distill_model_0/'\n",
    "# ]\n",
    "# seed_paths = [\n",
    "#     '../results/outputs_qqp_bert_base_1_seed23370/utama_distil/utama_distill_model_0/',\n",
    "#     '../results/outputs_qqp_bert_base_1_seed33370/utama_distil/utama_distill_model_0/',\n",
    "#     '../results/outputs_qqp_bert_base_1_seed43370/utama_distil/utama_distill_model_0/',\n",
    "#     '../results/outputs_qqp_bert_base_1_seed53370/utama_distil/utama_distill_model_0/',\n",
    "#     '../results/outputs_qqp_bert_base_1_seed63370/utama_distil/utama_distill_model_0/'\n",
    "# ]\n",
    "# print(seed_paths)\n",
    "\n",
    "# seed_path_prefix = \"%s_seed\"%MODEL_PATH\n",
    "# seed_paths = os.listdir(RESULT_PATH)\n",
    "# seed_paths = list(map(lambda x: os.path.join(RESULT_PATH, x), seed_paths))\n",
    "# seed_paths = list(filter(lambda x: x.startswith(seed_path_prefix), seed_paths))\n",
    "\n",
    "seed_paths = os.listdir(RESULT_PATH)\n",
    "seed_paths = list(map(lambda x: os.path.join(RESULT_PATH, x), seed_paths))\n",
    "# seed_paths = [\n",
    "#     '/raid/can/nli_models/qqp_bias/baseline/qqp_bert_base_bias_seed13370',\n",
    "#     '/raid/can/nli_models/qqp_bias/baseline/qqp_bert_base_bias_seed23370',\n",
    "#     '/raid/can/nli_models/qqp_bias/baseline/qqp_bert_base_bias_seed33370',\n",
    "# ]\n",
    "\n",
    "print(seed_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= TEST_SET: fever_dev =========\n",
      "../data/fact_verification/weighted_fever.dev.jsonl\n",
      "../results/outputs_fever_bert_base_1_seed23370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed33370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed43370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed53370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed63370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "factual score:\n",
      "[0.8569971195391263, 0.8640782525204033, 0.8542366778684589, 0.8593975036005761, 0.8556769083053288]\n",
      "0.8580772923667785 0.0034477069820969403\n",
      "TE:\n",
      "-0.03806660265283501 0.0014971721080326177\n",
      "TIE:\n",
      "-0.0022071173376407467 0.0014971721080326223\n",
      "TIE acc:\n",
      "[0.8565170427268363, 0.8649183869419107, 0.8542966874699952, 0.8602976476236198, 0.8557369179068651]\n",
      "0.8583533365338454 0.0038354727343253075\n",
      "The minimal epsilon for which Algorithm A is almost stochastically greater than algorithm B is  0.15127559340583618\n",
      "since epsilon <= 0.5 we will claim that A is better than B with significance level alpha= 0.05\n",
      "None\n",
      "TIE F1: {'SUPPORTS': [0.9315225707727621, 0.9332741904822255, 0.9321238264399898, 0.9346822636737274, 0.9309339754150298], 'REFUTES': [0.8781348456206679, 0.883942566932096, 0.8732965709577234, 0.8771154331901996, 0.8746363061353575]} {'SUPPORTS_mean_sd': [0.9325073653567468, 0.0013349668044022342], 'REFUTES_mean_sd': [0.8774251445672089, 0.0036850815690449173]}\n",
      "NIE:\n",
      "0.0027939038032344767 0.001428324288199867\n",
      "NIE acc:\n",
      "[0.8569971195391263, 0.8640782525204033, 0.8542366778684589, 0.8593975036005761, 0.8556769083053288]\n",
      "0.8580772923667785 0.0034477069820969403\n",
      "my query:\n",
      "[0.6656265002400384, 0.6742078732597215, 0.6653864618338934, 0.668446951512242, 0.6679068650984158]\n",
      "0.6683149303888622 0.003184785935664848\n",
      "The minimal epsilon for which Algorithm A is almost stochastically greater than algorithm B is  1.0\n",
      "since epsilon > 0.5 we will claim that A is not better than B with significance level alpha= 0.05\n",
      "None\n",
      "my query F1: {'SUPPORTS': [0.7379631963700529, 0.745164960182025, 0.7421138620082945, 0.7422875528357831, 0.7397191574724172], 'REFUTES': [0.6858751882653396, 0.6918890904379373, 0.6834124472573839, 0.6815794592491734, 0.6834814427600627]} {'SUPPORTS_mean_sd': [0.7414497457737146, 0.0024534364372758035], 'REFUTES_mean_sd': [0.6852475255939795, 0.0035901424983728033]}\n",
      "========= END ======== \n",
      "\n",
      "\n",
      "\n",
      "========= TEST_SET: fever_sym1 =========\n",
      "../data/fact_verification/weighted_fever_symmetric_v0.1.test.jsonl\n",
      "../results/outputs_fever_bert_base_1_seed23370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed33370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed43370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed53370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed63370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "factual score:\n",
      "[0.599721059972106, 0.592747559274756, 0.5885634588563459, 0.601115760111576, 0.5788005578800558]\n",
      "0.5921896792189679 0.00811327172789343\n",
      "TE:\n",
      "-0.06346213803304926 0.001453464559947062\n",
      "TIE:\n",
      "-0.026138778035978288 0.0014534645599470564\n",
      "TIE acc:\n",
      "[0.606694560669456, 0.595536959553696, 0.5899581589958159, 0.606694560669456, 0.5857740585774058]\n",
      "0.5969316596931659 0.008552139311997694\n",
      "The minimal epsilon for which Algorithm A is almost stochastically greater than algorithm B is  0.0009428572205816411\n",
      "since epsilon <= 0.5 we will claim that A is better than B with significance level alpha= 0.05\n",
      "None\n",
      "TIE F1: {'SUPPORTS': [0.7598870056497176, 0.7560627674750356, 0.7404255319148937, 0.7627118644067797, 0.7450980392156864], 'REFUTES': [0.5824561403508772, 0.5654450261780105, 0.5674255691768827, 0.5789473684210527, 0.5480427046263345]} {'SUPPORTS_mean_sd': [0.7528370417324226, 0.008620407839033848], 'REFUTES_mean_sd': [0.5684633617506314, 0.012107046289364785]}\n",
      "NIE:\n",
      "-0.022515593131462907 0.0013378113654378384\n",
      "NIE acc:\n",
      "[0.599721059972106, 0.592747559274756, 0.5885634588563459, 0.601115760111576, 0.5788005578800558]\n",
      "0.5921896792189679 0.00811327172789343\n",
      "my query:\n",
      "[0.6178521617852162, 0.6052998605299861, 0.6094839609483961, 0.6108786610878661, 0.603905160390516]\n",
      "0.6094839609483962 0.004911245986515769\n",
      "The minimal epsilon for which Algorithm A is almost stochastically greater than algorithm B is  0.0\n",
      "since epsilon = 0, algorithm A is stochatically dominant over B\n",
      "None\n",
      "my query F1: {'SUPPORTS': [0.7574468085106383, 0.7449275362318839, 0.7399999999999999, 0.7467811158798283, 0.7429378531073447], 'REFUTES': [0.6285714285714287, 0.6232394366197184, 0.6323268206039077, 0.6178010471204188, 0.6115107913669064]} {'SUPPORTS_mean_sd': [0.746418662745939, 0.0059546636638667765], 'REFUTES_mean_sd': [0.622689904856476, 0.007438251943400965]}\n",
      "========= END ======== \n",
      "\n",
      "\n",
      "\n",
      "========= TEST_SET: fever_sym2 =========\n",
      "../data/fact_verification/weighted_fever_symmetric_v0.2.test.jsonl\n",
      "../results/outputs_fever_bert_base_1_seed23370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed33370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed43370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed53370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "../results/outputs_fever_bert_base_1_seed63370/utama_distil/utama_distill_model_0/raw_fever.val.jsonl\n",
      "unique_labels:  ['SUPPORTS', 'REFUTES']\n",
      "factual score:\n",
      "[0.6544943820224719, 0.6544943820224719, 0.6460674157303371, 0.6558988764044944, 0.6460674157303371]\n",
      "0.6514044943820225 0.004387780716801481\n",
      "TE:\n",
      "-0.05739930579518715 0.0020401236287432424\n",
      "TIE:\n",
      "-0.01648472655618676 0.0020401236287432407\n",
      "TIE acc:\n",
      "[0.6629213483146067, 0.6601123595505618, 0.648876404494382, 0.6601123595505618, 0.648876404494382]\n",
      "0.6561797752808988 0.006050746974308434\n",
      "The minimal epsilon for which Algorithm A is almost stochastically greater than algorithm B is  0.0011769925058661994\n",
      "since epsilon <= 0.5 we will claim that A is better than B with significance level alpha= 0.05\n",
      "None\n",
      "TIE F1: {'SUPPORTS': [0.7819548872180451, 0.7860394537177542, 0.7680722891566266, 0.7807807807807808, 0.7683109118086696], 'REFUTES': [0.6973684210526315, 0.6884176182707993, 0.6820428336079079, 0.6896551724137931, 0.6799336650082919]} {'SUPPORTS_mean_sd': [0.7770316645363753, 0.00742638802455908], 'REFUTES_mean_sd': [0.6874835420706846, 0.006162812043485355]}\n",
      "NIE:\n",
      "-0.014425709978978334 0.0018935289062561099\n",
      "NIE acc:\n",
      "[0.6544943820224719, 0.6544943820224719, 0.6460674157303371, 0.6558988764044944, 0.6460674157303371]\n",
      "0.6514044943820225 0.004387780716801481\n",
      "my query:\n",
      "[0.6151685393258427, 0.6039325842696629, 0.6053370786516854, 0.6039325842696629, 0.5955056179775281]\n",
      "0.6047752808988764 0.006255915014415755\n",
      "The minimal epsilon for which Algorithm A is almost stochastically greater than algorithm B is  1.0\n",
      "since epsilon > 0.5 we will claim that A is not better than B with significance level alpha= 0.05\n",
      "None\n",
      "my query F1: {'SUPPORTS': [0.7112462006079027, 0.7047913446676972, 0.709480122324159, 0.6995377503852079, 0.6960486322188448], 'REFUTES': [0.6732673267326732, 0.6579804560260586, 0.6600331674958541, 0.651685393258427, 0.6467661691542288]} {'SUPPORTS_mean_sd': [0.7042208100407624, 0.0057629424110640735], 'REFUTES_mean_sd': [0.6579465025334483, 0.008980916673400272]}\n",
      "========= END ======== \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_set, label_key in zip(TEST_SETS, LABEL_KEYS):\n",
    "    print(\"========= TEST_SET: %s =========\"%test_set)\n",
    "    report_CMA(\n",
    "        model_path = \"\",\n",
    "        task = DATASET,\n",
    "        seed_path = seed_paths,\n",
    "\n",
    "        data_path = DATA_PATH,\n",
    "        test_set = test_set, ################\n",
    "        fusion = fuse.sum_fuse,\n",
    "#         input_a0 = input_a0,\n",
    "        estimate_c_config = ESTIMATE_C_DEFAULT_CONFIG,\n",
    "\n",
    "        correction = IS_CORRECTION,\n",
    "        ground_truth_key = label_key,\n",
    "#         model_pred_method = model_pred,\n",
    "\n",
    "        bias_val_pred_file = BIAS_VAL_PRED_FILE,\n",
    "        model_val_pred_file = MODEL_VAL_PRED_FILE,\n",
    "\n",
    "        entropy_threshold = -9999,\n",
    "    )\n",
    "    print(\"========= END ======== \\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
