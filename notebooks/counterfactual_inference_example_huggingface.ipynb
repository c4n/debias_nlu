{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9154d3bc",
   "metadata": {},
   "source": [
    "Here, we do causal inference on pre-compute data.\n",
    "\n",
    "\n",
    "to get raw prediction please see: /huggingface-model-predict-mnli-tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a33db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "  \n",
    "# setting path\n",
    "sys.path.append('../counterfactual')\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import fuse, causal_utils\n",
    "from kl_general import sharpness_correction, torch_mult_fuse\n",
    "\n",
    "\n",
    "TE_CONFIG = {\n",
    "    \"N_LABELS\": 3,\n",
    "    \"FUSE\": torch_mult_fuse,\n",
    "\n",
    "    \"EPOCHS\": 16,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"LEARNING_RATE\": 0.0001\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851e29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "\n",
    "# select data path\n",
    "data_path='~/debias_nlu/data/nli/'\n",
    "\n",
    "# select fusion method here\n",
    "fusion = fuse.sum_fuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81845c17",
   "metadata": {},
   "source": [
    "# sharpness correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55b4f4b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bias_dev = pd.read_json(\n",
    "    data_path+'dev_prob_korn_lr_overlapping_sample_weight_3class.jsonl', lines=True)\n",
    "bias_dev_score = [b for b in df_bias_dev['bias_probs']]\n",
    "bias_dev_score = np.array(bias_dev_score)\n",
    "# y1m0_dev = fusion(avg, bias_dev_score)\n",
    "df_bert_dev = pd.read_json('~/debias_nlu/data/nli/huggingface/huggingface_roberta_large_mnli_predict_dev_matched.jsonl', lines=True)\n",
    "y1m1prob_dev = []\n",
    "for p, h in zip(df_bert_dev['probs'], bias_dev_score):\n",
    "    new_y1m1 = fusion(np.array(p), h)\n",
    "    y1m1prob_dev.append(new_y1m1)\n",
    "c = sharpness_correction(bias_dev_score, y1m1prob_dev) \n",
    "c = c*np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "012e5875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11374858, 0.11374858, 0.11374858])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dabbcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_dev = pd.read_json('~/debias_nlu/data/nli/huggingface/huggingface_roberta_large_mnli_predict_dev_matched.jsonl', lines=True)\n",
    "c2 = sharpness_correction(bias_dev_score, df_bert_dev['probs'],config=TE_CONFIG) \n",
    "c2 = c2*np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b759da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54552078, 0.54552078, 0.54552078])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8642b3c",
   "metadata": {},
   "source": [
    "#  get score from the bias model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6107f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg prob\n",
    "#s score from bias model\n",
    "df_bias = pd.read_json(data_path+'hans_prob_korn_lr_overlapping_sample_weight_3class.jsonl', lines=True)\n",
    "# df_bias = pd.read_json(data_path+'test_prob_korn_lr_overlapping_sample_weight_3class.jsonl', lines=True)\n",
    "hans_score=[b for b in df_bias['bias_probs'] ]\n",
    "hans_score=np.array(hans_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af7d89",
   "metadata": {},
   "source": [
    "# load main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca0f31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert model predictions on HANS\n",
    "df_bert = pd.read_json('~/debias_nlu/data/nli/huggingface/huggingface_roberta_large_mnli_predict_hans.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91cc1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ent = []\n",
    "y1m1prob = []\n",
    "for p,h in zip(df_bert['probs'],hans_score):\n",
    "    new_y1m1 = fusion(np.array(p),h)\n",
    "    y1m1prob.append(new_y1m1)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b9d56",
   "metadata": {},
   "source": [
    "# corrected y1m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad12def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1m0prob = fusion(c,hans_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed8a9ec",
   "metadata": {},
   "source": [
    "# TIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b7a0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIE_A = []\n",
    "TE_model = []\n",
    "for p,b in zip(y1m1prob,y1m0prob):\n",
    "    TIE_A.append(p-b) # TIE  \n",
    "    \n",
    "for p,b in zip(df_bert['probs'],hans_score):    \n",
    "    TE_model.append(p-c2*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ecbd8",
   "metadata": {},
   "source": [
    "# Eval HANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57295d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {0:\"entailment\",1:\"contradiction\",2:\"neutral\"}\n",
    "t_labels = []\n",
    "for i in df_bert['probs']:\n",
    "    t_labels.append(key[np.argmax(i)])\n",
    "df_bert['label']=t_labels\n",
    "\n",
    "labels = []\n",
    "for i in TIE_A:\n",
    "    labels.append(key[np.argmax(i)])\n",
    "df_bert['TIE_debias_label']=labels\n",
    "\n",
    "\n",
    "labels = []\n",
    "for i in TE_model:\n",
    "    labels.append(key[np.argmax(i)])\n",
    "df_bert['TE_debias_label']=labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e0515be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ans=\"\"\n",
    "for idx, obj in enumerate(df_bert['label']):\n",
    "    text_ans = text_ans + \"ex\"+str(idx)+\",\"+obj+\"\\n\"   \n",
    "    \n",
    "text_ans_debias_tie=\"\"\n",
    "for idx, obj in enumerate(df_bert['TIE_debias_label']):\n",
    "    text_ans_debias_tie = text_ans_debias_tie + \"ex\"+str(idx)+\",\"+obj+\"\\n\"          \n",
    "    \n",
    "text_ans_debias_te=\"\"\n",
    "for idx, obj in enumerate(df_bert['TE_debias_label']):\n",
    "    text_ans_debias_te = text_ans_debias_te + \"ex\"+str(idx)+\",\"+obj+\"\\n\"           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81ceb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_label(label):\n",
    "    if label == \"entailment\":\n",
    "        return \"entailment\"\n",
    "    else:\n",
    "        return \"non-entailment\"\n",
    "\n",
    "guess_dict = {}\n",
    "for line in text_ans.split(\"\\n\"):\n",
    "    if len(line)>1:\n",
    "        parts = line.strip().split(\",\")\n",
    "        guess_dict[parts[0]] = format_label(parts[1])\n",
    "        \n",
    "guess_dict_debias_tie = {}\n",
    "for line in text_ans_debias_tie.split(\"\\n\"):\n",
    "    if len(line)>1:\n",
    "        parts = line.strip().split(\",\")\n",
    "        guess_dict_debias_tie[parts[0]] = format_label(parts[1])        \n",
    "        \n",
    " \n",
    "guess_dict_debias_te = {}\n",
    "for line in text_ans_debias_te.split(\"\\n\"):\n",
    "    if len(line)>1:\n",
    "        parts = line.strip().split(\",\")\n",
    "        guess_dict_debias_te[parts[0]] = format_label(parts[1])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5423e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9998\n",
      "subsequence: 1.0\n",
      "constituent: 0.9898\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.8938\n",
      "subsequence: 0.3378\n",
      "constituent: 0.1668\n",
      "avg: 0.7313333333333335\n"
     ]
    }
   ],
   "source": [
    "labels,baseline_avg=causal_utils.get_heur(guess_dict) # normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3258bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9994\n",
      "subsequence: 1.0\n",
      "constituent: 0.9886\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.9066\n",
      "subsequence: 0.3562\n",
      "constituent: 0.1866\n",
      "avg: 0.7395666666666667\n"
     ]
    }
   ],
   "source": [
    "labels,debias_avg=causal_utils.get_heur(guess_dict_debias_tie) # TIE_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b9eaf72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic entailed results:\n",
      "lexical_overlap: 0.9994\n",
      "subsequence: 1.0\n",
      "constituent: 0.9858\n",
      "\n",
      "Heuristic non-entailed results:\n",
      "lexical_overlap: 0.924\n",
      "subsequence: 0.3788\n",
      "constituent: 0.2164\n",
      "avg: 0.7507333333333334\n"
     ]
    }
   ],
   "source": [
    "labels,debias_avg=causal_utils.get_heur(guess_dict_debias_te) # TE_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
