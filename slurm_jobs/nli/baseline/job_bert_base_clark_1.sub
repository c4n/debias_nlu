#!/bin/bash -l
#SBATCH --error=/ist/users/canu/slurm_log/task.out.%j  # STDOUT output is written in slurm.out.JOBID
#SBATCH --output=/ist/users/canu/slurm_log/task.out.%j # STDOUT error is written in slurm.err.JOBID
#SBATCH --job-name=test_allennlp       # Job name
#SBATCH --mem=32GB                  # Memory request for this job
#SBATCH --nodes=1                   # The number of nodes
#SBATCH --partition=scads
#SBATCH --account=scads
#SBATCH --time=72:0:0                # Runing time 72 hours
#SBATCH --gpus=1                    # A number of GPUs  

 module load Anaconda3
 module load CUDA/11.0
 module load cuDNN/7
 module load HDF5

cd ~/debias_nlu
source ~/CI_env/bin/activate
allennlp train /ist/users/canu/debias_nlu/configs/nli/baseline/mnli_bert_base_clark_1.jsonnet -s /raid/can/nli_models/baseline/nli/outputs_bert_base_clark_1_seed43370/ --overrides '{ "random_seed": 43370, "numpy_seed": 4337, "pytorch_seed": 433}'
allennlp train /ist/users/canu/debias_nlu/configs/nli/baseline/mnli_bert_base_clark_1.jsonnet -s /raid/can/nli_models/baseline/nli/outputs_bert_base_clark_1_seed53370/ --overrides '{ "random_seed": 53370, "numpy_seed": 5337, "pytorch_seed": 533}'
allennlp train /ist/users/canu/debias_nlu/configs/nli/baseline/mnli_bert_base_clark_1.jsonnet -s /raid/can/nli_models/baseline/nli/outputs_bert_base_clark_1_seed63370/ --overrides '{ "random_seed": 63370, "numpy_seed": 6337, "pytorch_seed": 633}'
allennlp train /ist/users/canu/debias_nlu/configs/nli/baseline/mnli_bert_base_clark_1.jsonnet -s /raid/can/nli_models/baseline/nli/outputs_bert_base_clark_1_seed73370/ --overrides '{ "random_seed": 73370, "numpy_seed": 7337, "pytorch_seed": 733}' 
allennlp train /ist/users/canu/debias_nlu/configs/nli/baseline/mnli_bert_base_clark_1.jsonnet -s /raid/can/nli_models/baseline/nli/outputs_bert_base_clark_1_seed83370/ --overrides '{ "random_seed": 83370, "numpy_seed": 8337, "pytorch_seed": 833}'
 
#psql training_strategy=cross_entropy
#psql debiasing_method=none
#psql exp_remarks=bert base baseline try to imitate clark et al setting batch size 32
