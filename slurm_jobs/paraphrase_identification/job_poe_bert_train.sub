#!/bin/bash -l
#SBATCH --error=output/task.out.%j  # STDOUT output is written in slurm.out.JOBID
#SBATCH --output=output/task.out.%j # STDOUT error is written in slurm.err.JOBID
#SBATCH --job-name=qqp_baseline       # Job name
#SBATCH --mem=64GB                  # Memory request for this job
#SBATCH --nodes=1                   # The number of nodes
#SBATCH --partition=gpu-cluster
#SBATCH --account=scads
#SBATCH --time=72:0:0                # Runing time 72 hours
#SBATCH --gpus=1                    # A number of GPUs  

module load Anaconda3
module load CUDA/10.1
module load cuDNN/7
module load HDF5


TRANSFORMERS_OFFLINE=1
HF_DATASETS_OFFLINE=1

RESULT_DIR=${1:-results/outputs_qqp_poe_bert_1}

cd ~/debias_nlu
source ~/envNLI/bin/activate

python3 -c "import torch; print('# Visible GPUs: ', torch.cuda.device_count());"

allennlp train configs/paraphrase_identification/qqp_poe_bert_1.jsonnet \
    -s ${RESULT_DIR}_seed23370 \
    --include-package my_package \
    --overrides '{ "random_seed": 23370, "numpy_seed": 2337, "pytorch_seed": 233}'

allennlp train configs/paraphrase_identification/qqp_poe_bert_1.jsonnet \
    -s ${RESULT_DIR}_seed33370 \
    --include-package my_package \
    --overrides '{ "random_seed": 33370, "numpy_seed": 3337, "pytorch_seed": 333}'

allennlp train configs/paraphrase_identification/qqp_poe_bert_1.jsonnet \
    -s ${RESULT_DIR}_seed43370 \
    --include-package my_package \
    --overrides '{ "random_seed": 43370, "numpy_seed": 4337, "pytorch_seed": 433}'
